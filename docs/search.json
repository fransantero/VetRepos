[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About VetRepos",
    "section": "",
    "text": "The VetRepos project is a collaborative effort between European veterinary schools to create a progress test item database (Schaper et al. 2023).\n\n\n\n\nReferences\n\nSchaper, Elisabeth, Theo van Haeften, Jakob Wandall, Antti Iivanainen, Johanna Penell, Charles McLean Press, Pierre Lekeux, and Peter Holm. 2023. “Development of a Shared Item Repository for Progress Testing in Veterinary Education.” Frontiers in Veterinary Science 10 (November). https://doi.org/10.3389/fvets.2023.1296514."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "VetRepos modeling study (2024)",
    "section": "",
    "text": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students\nAntti Iivanainen† , Carlos Fernando Collares† , Jakob Wandall, Anna Parpala, Anne Nevgi, Riikka Keto-Timonen, Andrea Tipold, Elisabeth Schaper, Theo van Haeften, Tina Holberg Pihl, Charles McL Press, VetRepos consortium and Peter Holm\n†equal contribution\n\nAbstract\nThis study investigates the relationship between approaches to learning, self-perceived study burnout, and the level of subject knowledge among veterinary students. Veterinary educational programs are under regular development and would greatly benefit from detailed and accurate feedback on the students’ knowledge and proficiency, what factors influence this, and how students cope with their studies. The VetRepos consortium has developed and calibrated an item repository that tests knowledge and topics across the entire veterinary curriculum throughout all the study years. Two hundred forty-eight students from seven European veterinary educational institutions undertook the VetRepos test comprising a subset of the repository. The students also responded to a questionnaire assessing deep and unreflective learning approaches and self-perceived study burnout represented by exhaustion and cynicism. The relationship between these latent traits and the VetRepos test score was analyzed using structural equation modeling. The model failed the exact-fit test but was retained based on global fit indices, inter-item residual correlations, and standardized residual covariances. Root Mean Square Error of Approximation with robust standard errors and scaled test statistic was 0.049 [95% confidence interval 0.033–0.071], scaled and robust Comparative Fit Index 0.95 [0.90–0.98] and scaled Standardized Root Mean Square Residual 0.056 [0.049–0.071]. Measurement invariance across study years was not violated (\\(\\Delta\\)CFI = 0.00, \\(\\Delta\\chi^2\\)= 3.78, \\(\\Delta\\)df = 4, p-value = 0.44). However, measurement invariance could not be confirmed between genders or universities.\nAs expected by the test design, the VetRepos test score regressed on the study year (standardized regression coefficient = 0.68 [0.62–0.73]). In addition, a negative regression took place on the unreflective learning approach (–0.25 [–0.47––0.03]) and a positive regression on the deep approach (0.16 [0.03–0.28]). No direct association was observed with the perceived burnout in this study. Instead, a significant, medium-sized association was seen between the unreflective approach and the dimensions of self-perceived study burnout. No significant differences in the estimated levels of learning approaches or perceived burnout were found between study years.\nIn summary, the most important identified source of variation in VetRepos test scores unrelated to the study year originated from the learning approaches. The association between the VetRepos test score and self-perceived burnout was indirect. Our cross-sectional approach should be complemented in the future by longitudinal and person-oriented studies. Further investigations on the nature of the relationship between study burnout and the learning approaches are also warranted."
  },
  {
    "objectID": "R-code.html",
    "href": "R-code.html",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "",
    "text": "This html document contains the annotated script and copies of the tables and figures in the paper. The figures for the paper were exported as svg files and polished using Inkscape. The csv tables were loaded to excel, formatted and copied to the manuscript file for final polishing. Supplementary Tables 2A and 2B were exported as pdf files.\nThe anonymized input data have been deposited to the Finnish Social Science Data Archive https://urn.fi/urn:nbn:fi:fsd:T-FSD3873. The data do not include information on the gender or the university of the participants. Therefore a good number of the analyses won’t run. These chunks are indicated by red-colored text. Alongside of this html document, a pdf copy of the script is available from figshare at https://dx.doi.org/10.6084/m9.figshare.25470436.\nRendering of the html document was done using Quarto."
  },
  {
    "objectID": "R-code.html#required-packages",
    "href": "R-code.html#required-packages",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Required packages",
    "text": "Required packages\nThe script relies on the following packages. Please ensure that they are installed in your system.\nboot\ncorrplot\ndplyr\ndunn.test\neffectsize\nGGally\nggExtra\nggplot2\nGPArotation\ngt\nkableExtra\nknitr\nlavaan\nlattice\nlatticeExtra\nmirt\npatchwork  \npsych\npsychTools\nrmarkdown\nrsvg\nsemPlot\nsemTools\nstats"
  },
  {
    "objectID": "R-code.html#load-observations-data",
    "href": "R-code.html#load-observations-data",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Load observations data",
    "text": "Load observations data\nThe public anonymous data file (anonymous_data_VetRepos.csv) does not contain university and gender information.\n\nCode# The datafile \"rawdata_VetRepos.csv\" contains METADATA on gender and university\ndata1 &lt;- read.csv( \n  file = \"rawdata_VetRepos.csv\", \n  header=T, \n  dec = '.', \n  stringsAsFactors = T\n)\n\nn_iterations1 = 1000\nn_iterations2 = 2000"
  },
  {
    "objectID": "R-code.html#description-of-the-raw-data-group-variables-assign-data-to-raw_data-object-and-describe",
    "href": "R-code.html#description-of-the-raw-data-group-variables-assign-data-to-raw_data-object-and-describe",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Description of the raw data: group variables, assign data to raw_data object and describe",
    "text": "Description of the raw data: group variables, assign data to raw_data object and describe\n\nCodescale_deep &lt;- paste(\"deep_\", 1:4, sep ='')\nscale_unreflective4 &lt;- paste(\"unreflective_\", 1:4, sep ='')\nscale_unreflective3 &lt;- paste(\"unreflective_\", 1:3, sep ='')\nscale_cynicism &lt;- paste(\"cynicism_\", 1:3, sep = '')\nscale_exhaustion &lt;- paste(\"exhaustion_\", 1:4, sep = '')\nscale_inadequacy &lt;- paste(\"inadequacy_\", 1:2, sep = '')\nscale_all &lt;- c(\n  scale_deep,\n  scale_unreflective4,\n  scale_cynicism,\n  scale_exhaustion,\n  scale_inadequacy\n)\n\n\n# divide score by 100 to align variance with the other observed variables\ndata1[\"score_div100\"] &lt;- data1[\"vetrepos_score\"]/100 \n\n# raw sumscores\ndata1[\"raw_deep\"] &lt;- apply(data1[paste(\"deep_\", 1:4, sep ='')], 1, sum)\ndata1[\"raw_unreflective4\"] &lt;- apply( # all four indicators\n  data1[paste(\"unreflective_\", 1:4, sep ='')], 1, sum\n)\ndata1[\"raw_unreflective3\"] &lt;- apply( # indicators 1, 2 and 3\n  data1[paste(\"unreflective_\", 1:3, sep ='')], 1, sum\n)\ndata1[\"raw_unreflective\"] &lt;- data1[\"raw_unreflective3\"]\ndata1[\"raw_cynicism\"] &lt;- apply(data1[paste(\"cynicism_\", 1:3, sep = '')], 1, sum)\ndata1[\"raw_exhaustion\"] &lt;- apply(data1[paste(\"exhaustion_\", 1:4, sep = '')], 1, sum)\ndata1[\"raw_inadequacy\"] &lt;- apply(data1[paste(\"inadequacy_\", 1:2, sep = '')], 1, sum)\ndata1[\"raw_burnout\"] &lt;- apply(\n  data1[,c(\"raw_cynicism\", \"raw_exhaustion\", \"raw_inadequacy\")], \n  1, \n  sum\n)\n\n# Assign everything to raw_data and describe\nraw_data &lt;- data1\nkbl(round(describe(raw_data),2))\n\n\n\nDescription of the rawdata\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nuniversity*\n1\n248\n4.49\n2.08\n6.00\n4.60\n1.48\n1.0\n7\n6.0\n-0.47\n-1.35\n0.13\n\n\ngender\n2\n248\n1.89\n0.34\n2.00\n1.98\n0.00\n1.0\n3\n2.0\n-1.84\n3.67\n0.02\n\n\nstudy_year\n3\n248\n2.88\n1.49\n3.00\n2.77\n1.48\n1.0\n6\n5.0\n0.50\n-0.80\n0.09\n\n\nvetrepos_score\n4\n248\n507.48\n92.51\n508.00\n507.16\n103.04\n290.0\n700\n410.0\n0.03\n-0.75\n5.87\n\n\ndeep_1\n5\n248\n2.19\n0.78\n2.00\n2.24\n1.48\n0.0\n4\n4.0\n-0.35\n0.01\n0.05\n\n\ndeep_2\n6\n248\n2.22\n0.87\n2.00\n2.25\n1.48\n0.0\n4\n4.0\n-0.29\n-0.67\n0.06\n\n\ndeep_3\n7\n248\n2.76\n0.76\n3.00\n2.79\n0.00\n0.0\n4\n4.0\n-0.71\n0.67\n0.05\n\n\ndeep_4\n8\n248\n2.77\n0.74\n3.00\n2.80\n0.00\n0.0\n4\n4.0\n-0.73\n0.85\n0.05\n\n\nunreflective_1\n9\n248\n1.57\n0.95\n1.00\n1.58\n1.48\n0.0\n4\n4.0\n0.19\n-0.88\n0.06\n\n\nunreflective_2\n10\n248\n1.53\n0.94\n1.00\n1.53\n1.48\n0.0\n4\n4.0\n0.38\n-0.60\n0.06\n\n\nunreflective_3\n11\n248\n1.17\n0.84\n1.00\n1.10\n0.00\n0.0\n4\n4.0\n0.68\n0.30\n0.05\n\n\nunreflective_4\n12\n248\n2.87\n0.81\n3.00\n2.94\n0.00\n0.0\n4\n4.0\n-0.91\n1.13\n0.05\n\n\ncynicism_1\n13\n248\n1.54\n1.04\n1.00\n1.51\n1.48\n0.0\n4\n4.0\n0.22\n-0.74\n0.07\n\n\ncynicism_2\n14\n248\n1.01\n1.03\n1.00\n0.88\n1.48\n0.0\n4\n4.0\n0.85\n-0.15\n0.07\n\n\ncynicism_3\n15\n248\n0.94\n1.04\n1.00\n0.79\n1.48\n0.0\n4\n4.0\n0.87\n-0.30\n0.07\n\n\nexhaustion_1\n16\n248\n2.40\n0.99\n3.00\n2.43\n1.48\n0.0\n4\n4.0\n-0.50\n-0.39\n0.06\n\n\nexhaustion_2\n17\n248\n1.52\n1.23\n1.00\n1.46\n1.48\n0.0\n4\n4.0\n0.36\n-1.03\n0.08\n\n\nexhaustion_3\n18\n248\n2.19\n1.00\n2.00\n2.19\n1.48\n0.0\n4\n4.0\n-0.16\n-0.64\n0.06\n\n\nexhaustion_4\n19\n248\n1.61\n1.14\n1.00\n1.59\n1.48\n0.0\n4\n4.0\n0.20\n-0.97\n0.07\n\n\ninadequacy_1\n20\n248\n1.96\n1.10\n2.00\n1.99\n1.48\n0.0\n4\n4.0\n-0.07\n-0.88\n0.07\n\n\ninadequacy_2\n21\n248\n1.75\n1.15\n2.00\n1.76\n1.48\n0.0\n4\n4.0\n0.10\n-1.05\n0.07\n\n\nscore_div100\n22\n248\n5.07\n0.93\n5.08\n5.07\n1.03\n2.9\n7\n4.1\n0.03\n-0.75\n0.06\n\n\nraw_deep\n23\n248\n9.94\n2.33\n10.00\n10.02\n1.48\n0.0\n16\n16.0\n-0.52\n1.08\n0.15\n\n\nraw_unreflective4\n24\n248\n7.13\n2.40\n7.00\n7.08\n2.97\n1.0\n14\n13.0\n0.23\n-0.26\n0.15\n\n\nraw_unreflective3\n25\n248\n4.27\n2.09\n4.00\n4.20\n1.48\n0.0\n11\n11.0\n0.40\n-0.16\n0.13\n\n\nraw_unreflective\n26\n248\n4.27\n2.09\n4.00\n4.20\n1.48\n0.0\n11\n11.0\n0.40\n-0.16\n0.13\n\n\nraw_cynicism\n27\n248\n3.48\n2.64\n3.00\n3.29\n2.97\n0.0\n12\n12.0\n0.60\n-0.13\n0.17\n\n\nraw_exhaustion\n28\n248\n7.72\n3.26\n8.00\n7.70\n2.97\n1.0\n16\n15.0\n0.10\n-0.55\n0.21\n\n\nraw_inadequacy\n29\n248\n3.71\n1.87\n4.00\n3.73\n2.97\n0.0\n8\n8.0\n0.02\n-0.76\n0.12\n\n\nraw_burnout\n30\n248\n14.92\n6.33\n15.00\n14.84\n5.93\n1.0\n34\n33.0\n0.12\n-0.39\n0.40"
  },
  {
    "objectID": "R-code.html#model-structures",
    "href": "R-code.html#model-structures",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Model structures",
    "text": "Model structures\n\nMeasurement model\nFull structural equation model\nFull structural equation model with the covariance term cynicism_1~~exhaustion_1\nMeasurement invariance for study years: constrained and unconstrained models\nMeasurement invariance for genders: constrained and unconstrained models\n\n\nCode# measurement model\nm_measurement = ' \n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n'\n\n# full structural equation model\nm_full_SEM &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n  \n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n'\n\n# full SEM with covariance term cynicism_1~~exhaustion_1\nm_full_SEM_cov &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n  \n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n  cynicism_1 ~~ exhaustion_1\n'\n\n# models for assessing measurement invariance\nm_constrained_syear &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n\n  # mimic regressions\n  f_deep ~ 0*study_year\n  f_unreflective ~ 0*study_year\n  f_cynicism ~ 0*study_year\n  f_exhaustion ~ 0*study_year\n\n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n'\n\nm_unconstrained_syear &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n\n  # mimic regressions\n  f_deep ~ study_year\n  f_unreflective ~ study_year\n  f_cynicism ~ study_year\n  f_exhaustion ~ study_year\n\n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n'\n\nm_constrained_gender &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n\n  # mimic regressions\n  f_deep ~ 0*gender\n  f_unreflective ~ 0*gender\n  f_cynicism ~ 0*gender\n  f_exhaustion ~ 0*gender\n\n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n'\n\nm_unconstrained_gender &lt;- '\n  # measurement model\n  f_deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  f_unreflective =~ unreflective_1 + unreflective_2 + unreflective_3\n  f_cynicism =~ cynicism_1 + cynicism_2 + cynicism_3\n  f_exhaustion =~ exhaustion_1 + exhaustion_2 + exhaustion_3 + exhaustion_4\n\n  # regressions\n  score_div100 ~ f_deep + study_year  + f_unreflective + f_cynicism + f_exhaustion\n\n  # mimic regressions\n  f_deep ~ gender\n  f_unreflective ~ gender\n  f_cynicism ~ gender\n  f_exhaustion ~ gender\n\n  # covariances\n  f_cynicism ~~ f_exhaustion\n  f_unreflective ~~ f_cynicism + f_exhaustion + f_deep\n'"
  },
  {
    "objectID": "R-code.html#preparation-of-weights",
    "href": "R-code.html#preparation-of-weights",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Preparation of weights",
    "text": "Preparation of weights\nThe goal is to control the effect of university F. University E is removed to avoid introducing an overly strong emphasis on its five students.\nThe following code chunk won’t run on anonymous data.\n\nCode# raw data exluding university E \ndata_wt &lt;- subset(raw_data, university != 'E') \ndata_wt$university &lt;- factor(\n  data_wt$university, \n  levels = c('A', 'B', 'C', 'D', 'F', 'G')\n)\n\n# Calculate weights as the ratio of desired to observed proportions\ngroup_table &lt;- table(data_wt$university)\ndesired_proportions &lt;- rep(\n  1/length(levels(data_wt$university)),\n  length(levels(data_wt$university))\n)\nweights &lt;- desired_proportions / (group_table / sum(group_table))\ndata_wt$weights &lt;- as.numeric(weights[as.character(data_wt$university)])\n\ntable_weights &lt;- data.frame(cbind(\n  count = table(data_wt$university),\n  weights)\n)\ntable_weights[\"weighted count\"] &lt;- with(table_weights, count*weights)\ntable_weights &lt;- rbind(table_weights, sum = apply(table_weights, 2, sum))\n\nkbl(\n  round(table_weights,2),\n  caption = \"Weights per university\",\n) \n\n\n\nWeights per university\n\n\ncount\nweights\nweighted count\n\n\n\nA\n31\n1.31\n40.5\n\n\nB\n32\n1.27\n40.5\n\n\nC\n27\n1.50\n40.5\n\n\nD\n18\n2.25\n40.5\n\n\nF\n105\n0.39\n40.5\n\n\nG\n30\n1.35\n40.5\n\n\nsum\n243\n8.06\n243.0"
  },
  {
    "objectID": "R-code.html#fit-models-exact-fit-test-and-global-fit-indices",
    "href": "R-code.html#fit-models-exact-fit-test-and-global-fit-indices",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Fit models, exact fit test and global fit indices",
    "text": "Fit models, exact fit test and global fit indices\n\nunweighted and weighted data\nfull SE model fails the exact fit test\nfull SEM with vs. without covariance term between cynicism_1 and exhaustion_1\n\n\nCode# global fit indices\nglobal_fit_stats &lt;- c(\n  'rmsea.robust',\n  'cfi.robust',\n  'tli.scaled',\n  'srmr'\n)\n\n### unweighted complete data\n# measurement model, CFA\nfit_measurement &lt;-  cfa(\n  model = m_measurement, \n  data = raw_data,\n  estimator = 'MLM',\n  std.lv=T,\n  fixed.x = 'default')\n# exact-fit test\nfitMeasures(fit_measurement, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\")) \n\n chisq.scaled     df.scaled pvalue.scaled \n      113.622        71.000         0.001 \n\nCode# full structural equation model\nset.seed(1234)\nfit_fullSEM &lt;- sem(\n  model = m_full_SEM, # full structural equation model\n  data = raw_data,\n  std.ov = T,\n  mimic = 'lavaan',\n  estimator = \"MLM\",\n  fixed.x = 'default'\n )\n# exact-fit test\nfitMeasures(fit_fullSEM, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\")) \n\n chisq.scaled     df.scaled pvalue.scaled \n      148.202        95.000         0.000 \n\nCode# pvalue\nfit_fullSEM@test$satorra.bentler$pvalue # 0.0003948651\n\n[1] 0.0003948651\n\nCode# full structural equation model with covariance term cynicism_1~~exhaustion_1\nset.seed(1234)\nfit_fullSEM_cov &lt;- sem(\n  model = m_full_SEM_cov, # full structural equation model\n  data = raw_data,\n  std.ov = T,\n  mimic = 'lavaan',\n  estimator = \"MLM\",\n  fixed.x = 'default'\n )\n# exact-fit test\nfitMeasures(fit_fullSEM_cov, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\")) # pvalue\n\n chisq.scaled     df.scaled pvalue.scaled \n      131.806        94.000         0.006 \n\nCodefit_fullSEM_cov@test$satorra.bentler$pvalue \n\n[1] 0.00615839\n\nCode# comparison between fit_fullSEM and fit_fullSEM_cov\ndelta_cov_fit &lt;- lavTestLRT(fit_fullSEM, fit_fullSEM_cov)\n\ndelta_chiq &lt;- delta_cov_fit[2, 'Chisq'] - delta_cov_fit[1, 'Chisq']\npval &lt;- pchisq(delta_chiq, 4, lower.tail = F)\ndelta_cov_fit[2, 'Chisq diff'] &lt;- delta_chiq\ndelta_cov_fit[2, 'Pr(&gt;Chisq)'] &lt;- pval\ndelta_cov_fit # model comparison fit_fullSEM vs. fit_fullSEM_cov\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nDf diff\nPr(&gt;Chisq)\n\n\n\nfit_fullSEM_cov\n94\n7332.042\n7476.092\n141.4301\nNA\nNA\nNA\n\n\nfit_fullSEM\n95\n7347.718\n7488.255\n159.1060\n17.67591\n1\n0.0014277\n\n\n\n\n\n\nThe following code chunks won’t run on anonymous data.\n\nCode### weighted data\n# measurement model, weighted data excluding university E\nset.seed(1234)\nfit_weighted_measurement &lt;-  cfa(\n  model = m_measurement, \n  data = data_wt, # raw_data without university E\n  sampling.weights = \"weights\", # weight matrix\n  estimator = 'MLM',\n  std.lv=T,\n  fixed.x = 'default')\n# exact-fit test\nfitMeasures(fit_weighted_measurement, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\"))\n\n chisq.scaled     df.scaled pvalue.scaled \n      124.966        71.000         0.000 \n\nCode# pvalue\nfit_weighted_measurement@test$satorra.bentler$pvalue \n\n[1] 8.118573e-05\n\nCode# full SE model with weight matrix but without university E\nset.seed(1234)\nfit_weighted_fullSEM &lt;- sem(\n  model = m_full_SEM, # full structural equation model\n  data = data_wt,\n  sampling.weights = \"weights\",\n  std.ov = T,\n  mimic = 'lavaan',\n  estimator = \"MLM\",\n  fixed.x = 'default'\n )\n# exact-fit test\nfitMeasures(fit_weighted_fullSEM, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\"))\n\n chisq.scaled     df.scaled pvalue.scaled \n      147.914        95.000         0.000 \n\nCode# pvalue\nfit_weighted_fullSEM@test$satorra.bentler$pvalue \n\n[1] 0.0004177953\n\nCode# full SE model with covariance term cynicism_1~~exhaustion_1 and \n# weight matrix but exluding data from university E\nset.seed(1234)\nfit_weighted_fullSEM_cov &lt;- sem(\n  model = m_full_SEM_cov, # full structural equation model\n  data = data_wt,\n  sampling.weights = \"weights\",\n  std.ov = T,\n  mimic = 'lavaan',\n  estimator = \"MLM\",\n  fixed.x = 'default'\n )\n\n# exact-fit test\nfitMeasures(fit_weighted_fullSEM_cov, c(\"chisq.scaled\", \"df.scaled\", \"pvalue.scaled\"))\n\n chisq.scaled     df.scaled pvalue.scaled \n      126.109        94.000         0.015 \n\nCode# pvalue\nfit_weighted_fullSEM_cov@test$satorra.bentler$pvalue\n\n[1] 0.01516942"
  },
  {
    "objectID": "R-code.html#down-sampling-university-f",
    "href": "R-code.html#down-sampling-university-f",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Down sampling university F",
    "text": "Down sampling university F\nDown sampling of data, 1000 iterations. Sample size (N=173 including 30 from university F). The code won’t run on anonymous data without university information.\nModel fitting:\n\nmeasurement model\nfull SE model\n\nGlobal fit indices from fitted models:\n\n‘rmsea.robust’,\n‘cfi.robust’,\n‘tli.scaled’,\n‘srmr’\n\nStore global fit, local fit, and model parameters in R data objects:\n\nglobal fit\n\ndownsampled_data_fit_indices (measurement model)\ndownsampled_data_fit_indices_fullSEM (full SEM)\ndownsampled_data_fit_indices_fullSEM_cov (full SEM with cyn1~~exh1 covariance)\n\n\nlocal fit\n\ndownsampled_data_residual_correlations (full SEM)\ndownsampled_data_residual_correlations_cov (full SEM with cyn1~~exh1 covariance)\ndownsampled_data_standardized_residual_covariances (full SEM)\ndownsampled_data_standardized_residual_covariances_cov (full SEM with cyn1~~exh1 covariance)\n\n\nmodel parameters\n\ndownsampled_data_parameter_list (measurement model)\ndownsampled_data_parameter_list_fullSEM (full SEM)\ndownsampled_data_parameter_list_fullSEM_cov (full SEM with cyn1~~exh1 covariance)\n\n\n\nThe following code chunk won’t run on anonymous data.\n\nCode# global fit placeholders\ndownsampled_data_fit_indices &lt;- list() \ndownsampled_data_fit_indices_fullSEM &lt;- list()\ndownsampled_data_fit_indices_fullSEM_cov &lt;- list()\n# local fit placeholders (only for full SEM)\ndownsampled_data_residual_correlations &lt;- list() \ndownsampled_data_residual_correlations_cov &lt;- list() \ndownsampled_data_standardized_residual_covariances &lt;- list() \ndownsampled_data_standardized_residual_covariances_cov &lt;- list() \n# parameter estimates placeholders\ndownsampled_data_parameter_list &lt;- list() \ndownsampled_data_parameter_list_fullSEM &lt;- list()\ndownsampled_data_parameter_list_fullSEM_cov &lt;- list()\n\nn_iterations &lt;- n_iterations1\ndata &lt;- raw_data\ns = 30 # sample size\n\nfor (i in 1:n_iterations) {\n  # draw a sample from university F and\n  # combine with the observations from the other universities\n  uniF_idx &lt;- which(data$university == 'F') \n  sampled_idx &lt;- sample(uniF_idx, length(uniF_idx) * (s/length(uniF_idx)))\n  downsampled_data &lt;- data[c(sampled_idx, which(data$university != 'F')), ]\n\n  # Fit the measurement model to the down-sampled dataset\n  fit_downsampled &lt;-  cfa(\n    model = m_measurement, # measurement model\n    data = downsampled_data,\n    estimator = 'MLM',\n    std.lv=T,\n    fixed.x = 'default'\n  )\n  \n  # Fit the full SE model to down-sampled dataset \n  fit_downsampled_fullSEM &lt;- sem(\n    model = m_full_SEM, # full structural equation model\n    data = downsampled_data,\n    std.ov = T,\n    mimic = 'lavaan',\n    estimator = \"MLM\",\n    fixed.x = 'default'\n  )\n  \n  # Fit the full SE model with covariance term to the down-sampled dataset \n  fit_downsampled_fullSEM_cov &lt;- sem(\n    model = m_full_SEM_cov, # full SEM with cyn1~~exh1 covariance\n    data = downsampled_data,\n    std.ov = T,\n    mimic = 'lavaan',\n    estimator = \"MLM\",\n    fixed.x = 'default'\n  )\n\n  # Save global fit indices, residuals and parameter estimates\n  downsampled_data_fit_indices [[i]] &lt;- fitMeasures(\n    fit_downsampled, \n    global_fit_stats\n  )\n  downsampled_data_fit_indices_fullSEM [[i]] &lt;- fitMeasures(\n    fit_downsampled_fullSEM, \n    global_fit_stats\n  )\n  downsampled_data_residual_correlations[[i]] &lt;- lavResiduals(\n    fit_downsampled_fullSEM, \n    type = 'cor'\n  )$cov\n  downsampled_data_standardized_residual_covariances[[i]] &lt;- lavResiduals(\n    fit_downsampled_fullSEM, \n    type = 'raw'\n  )$cov.z\n  downsampled_data_parameter_list[[i]] &lt;- standardizedSolution(\n    fit_downsampled, \n    output = 'data.frame'\n  )\n  downsampled_data_parameter_list_fullSEM[[i]] &lt;- standardizedSolution(\n    fit_downsampled_fullSEM, \n    output = 'data.frame'\n  )\n  downsampled_data_fit_indices_fullSEM_cov[[i]] &lt;- fitMeasures(\n    fit_downsampled_fullSEM_cov, \n    global_fit_stats\n  )\n  downsampled_data_residual_correlations_cov[[i]] &lt;- lavResiduals(\n    fit_downsampled_fullSEM_cov, \n    type = 'cor'\n  )$cov\n  downsampled_data_standardized_residual_covariances_cov[[i]] &lt;- lavResiduals(\n    fit_downsampled_fullSEM_cov, \n    type = 'raw'\n  )$cov.z\n  downsampled_data_parameter_list_fullSEM_cov[[i]] &lt;- standardizedSolution(\n    fit_downsampled_fullSEM_cov, \n    output = 'data.frame'\n  )\n}"
  },
  {
    "objectID": "R-code.html#complete-data-with-factor-scores",
    "href": "R-code.html#complete-data-with-factor-scores",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Complete data with factor scores",
    "text": "Complete data with factor scores\n\nCodelavaan_traits &lt;- lavPredict(\n  object = fit_fullSEM, \n  type = 'lv'\n)\n\ncomplete_data &lt;- cbind(\n  raw_data,\n  lavaan_traits\n) \n\nkbl(\n  round(describe(lavaan_traits), 2),\n  caption = \"Description of the latent traits\",\n) \n\n\n\nDescription of the latent traits\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nf_deep\n1\n248\n0\n0.45\n0.11\n0.02\n0.24\n-1.90\n0.92\n2.82\n-0.59\n0.98\n0.03\n\n\nf_unreflective\n2\n248\n0\n0.54\n-0.05\n-0.01\n0.50\n-1.17\n1.57\n2.74\n0.29\n-0.23\n0.03\n\n\nf_cynicism\n3\n248\n0\n0.64\n-0.07\n-0.05\n0.74\n-0.93\n2.07\n3.00\n0.60\n-0.25\n0.04\n\n\nf_exhaustion\n4\n248\n0\n0.57\n-0.01\n0.00\n0.64\n-1.20\n1.59\n2.79\n0.11\n-0.54\n0.04"
  },
  {
    "objectID": "R-code.html#table-1-distribution-of-the-participants",
    "href": "R-code.html#table-1-distribution-of-the-participants",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 1: Distribution of the participants",
    "text": "Table 1: Distribution of the participants\nThe following code chunks won’t run on anonymous data.\n\nCode# Table 1A\nt1a &lt;- table(raw_data['university'])\ns &lt;- sum(t1a)\nattr(s, which = 'names') &lt;- \"sum\"\ntable1A &lt;- t(append(t1a, s))\n\nkbl(\n  table1A,\n  caption = \"Table 1A. Distribution of students by universities\",\n) \n\n\n\nTable 1A. Distribution of students by universities\n\nA\nB\nC\nD\nE\nF\nG\nsum\n\n\n31\n32\n27\n18\n5\n105\n30\n248\n\n\n\n\nCode# Table 1B\ndata_table1B &lt;- subset(raw_data, gender != 3)\nmB &lt;- matrix(\n  data = addmargins(xtabs(~  gender + study_year, data=data_table1B)), \n  byrow=F,\n  nrow=3,\n  dimnames = list(c('males', 'females', 'sum'), c(as.character(1:6), \"sum\"))\n)\ntable1B &lt;- data.frame(mB)\ncolnames(table1B) = attr(mB, \"dimnames\")[[2]]\n\nkbl(\n  table1B,\n  caption = \"Table 1B. Gender by study year\",\n)\n\n\n\nTable 1B. Gender by study year\n\n\n1\n2\n3\n4\n5\n6\nsum\n\n\n\nmales\n4\n8\n3\n6\n5\n3\n29\n\n\nfemales\n44\n64\n41\n33\n23\n12\n217\n\n\nsum\n48\n72\n44\n39\n28\n15\n246\n\n\n\n\n\nCode# Table 1C obs/exp number of students by study year and university\ndata &lt;- xtabs(~ university + study_year, raw_data)\n(chisq &lt;- chisq.test(data, simulate.p.value = T))\n\n\n    Pearson's Chi-squared test with simulated p-value (based on 2000\n    replicates)\n\ndata:  data\nX-squared = 116.43, df = NA, p-value = 0.0004998\n\nCodemC &lt;- matrix(\n  data=ftable(round(data/chisq$expected, 2)),\n  byrow = FALSE,\n  nrow = 7,\n  dimnames = list(LETTERS[1:7], 1:6)\n)\ntable1C &lt;- data.frame(mC)\ncolnames(table1C) &lt;-  attr(mC, \"dimnames\")[[2]]\n\nkbl(\n  table1C, \n  caption = \"Table 1C. Observed/expected number of students by study year and university\",\n) \n\n\n\nTable 1C. Observed/expected number of students by study year and university\n\n\n1\n2\n3\n4\n5\n6\n\n\n\nA\n1.14\n0.44\n1.27\n1.23\n1.71\n0.53\n\n\nB\n0.32\n0.32\n1.23\n1.39\n1.38\n4.13\n\n\nC\n0.00\n0.38\n1.04\n2.59\n1.64\n1.84\n\n\nD\n0.28\n1.51\n0.63\n0.71\n1.97\n0.92\n\n\nE\n0.00\n0.68\n1.13\n2.54\n0.00\n3.31\n\n\nF\n1.88\n1.36\n0.86\n0.30\n0.25\n0.00\n\n\nG\n0.00\n1.36\n1.13\n1.27\n1.48\n0.55\n\n\n\n\n\n\nComparison between universities\nThe following code chunks won’t run on anonymous data.\n\nCode# Differences of the student profiles between universities\ncategories &lt;- levels(raw_data$university)\nalpha = 0.05\n\npairwise_comparison &lt;- data.frame(\n  university_1 = character(),\n  university_2 = character(),\n  chisq_stats = double(),\n  pvalue = double()\n) \n\ncombinations &lt;- combn(categories, 2)\nfor (i in 1:ncol(combinations)) {\n  subset &lt;- raw_data[raw_data$university %in% combinations[, i], ]\n  set.seed(1234)\n  chi_test_result &lt;- chisq.test(\n    simulate.p.value = T,\n    xtabs(~ university + study_year, subset)[combinations[,i], ]\n  )\n  pairwise_comparison &lt;- rbind(\n    pairwise_comparison, \n    c(\n      combinations[1, i], \n      combinations[2, i], \n      chi_test_result$statistic, \n      chi_test_result$p.value\n    )\n  )\n}\n\ncolnames(pairwise_comparison) &lt;- c(\n  \"university_1\", \n  \"university_2\", \n  \"chisq_statistic\", \n  \"pvalue\"\n)\npairwise_comparison$chisq_statistic &lt;- round(\n  as.double(pairwise_comparison$chisq_statistic),\n  2\n)\npairwise_comparison$pvalue &lt;- as.double(pairwise_comparison$pvalue) \npairwise_comparison$adj_pvalue &lt;- with(pairwise_comparison, p.adjust(pvalue, \"fdr\"))\npairwise_comparison$significant_at_alpha &lt;- with(\n  pairwise_comparison,\n  ifelse(adj_pvalue &lt; alpha, \"TRUE\", \"\")\n)\n\n# placeholder matrix for the pairwise chisq statistics\nmat &lt;- matrix(\n  NA, \n  nrow = length(categories), \n  ncol = length(categories),\n  dimnames = list(categories, categories)\n)\n\n# Fill the lower triangle with the pairwise values\nfor (i in 1:nrow(pairwise_comparison)) {\n  # indices\n  row_index &lt;- which(categories == pairwise_comparison$university_1[i])\n  col_index &lt;- which(categories == pairwise_comparison$university_2[i])\n\n  # lower triangle\n  if (row_index &gt; col_index) { \n    mat[row_index, col_index] &lt;- pairwise_comparison[i,\"chisq_statistic\" ]\n  } else if (row_index &lt; col_index) { \n    mat[col_index, row_index] &lt;- pairwise_comparison[i, \"chisq_statistic\"]\n  }\n}\n\n\n\nCode# remove diagonal, round and replace NA's with blanks\nmat &lt;- round(data.frame(mat[-1, -7]), 2) %&gt;%\n  dplyr::mutate(across(everything(), ~ replace(.x, is.na(.x), \"\")))\n\n# chisq values from pairwise comparisons\nkbl(\n  mat,\n  caption = \"Chi^2 statistics from pairwise comparisons between universities\"\n)\n\n\n\nChi^2 statistics from pairwise comparisons between universities\n\n\nA\nB\nC\nD\nE\nF\n\n\n\nB\n8.52\n\n\n\n\n\n\n\nC\n9.81\n5.11\n\n\n\n\n\n\nD\n8.13\n10.63\n10.52\n\n\n\n\n\nE\n5.27\n2.18\n1.46\n5.04\n\n\n\n\nF\n26.99\n56.76\n58.73\n22.01\n32.87\n\n\n\nG\n11.15\n12.95\n7.83\n3.11\n4.13\n29.13\n\n\n\n\n\n\n\nCode# significant pairwise comparisons\nsignificant_differences &lt;- subset(pairwise_comparison, significant_at_alpha == \"TRUE\")\nkbl(\n  significant_differences,\n  align = 'cccccc',\n  row.names = FALSE,\n  caption = \"Significant differences at alpha = 0.05\",\n) \n\n\n\nSignificant differences at alpha = 0.05\n\nuniversity_1\nuniversity_2\nchisq_statistic\npvalue\nadj_pvalue\nsignificant_at_alpha\n\n\n\nA\nF\n26.99\n0.0004998\n0.0026237\nTRUE\n\n\nB\nF\n56.76\n0.0004998\n0.0026237\nTRUE\n\n\nB\nG\n12.95\n0.0144928\n0.0434783\nTRUE\n\n\nC\nF\n58.73\n0.0004998\n0.0026237\nTRUE\n\n\nD\nF\n22.01\n0.0014993\n0.0052474\nTRUE\n\n\nE\nF\n32.87\n0.0009995\n0.0041979\nTRUE\n\n\nF\nG\n29.13\n0.0004998\n0.0026237\nTRUE"
  },
  {
    "objectID": "R-code.html#table-2-factor-loadings-on-the-learning-approach-indicator-items-cfa-efa",
    "href": "R-code.html#table-2-factor-loadings-on-the-learning-approach-indicator-items-cfa-efa",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 2: Factor loadings on the learning approach indicator items (CFA & EFA)",
    "text": "Table 2: Factor loadings on the learning approach indicator items (CFA & EFA)\n\nCode# CFA\nm_approaches = ' # measurement model for learning approaches\n  deep =~ deep_1 + deep_2 + deep_3 + deep_4\n  unreflective =~ unreflective_1 + unreflective_2 + unreflective_3 + unreflective_4\n'\n\ndata_tableX = raw_data[c(scale_deep, scale_unreflective4)]\nfit_approaches_cfa &lt;-  cfa(\n  model = m_approaches, \n  data = data_tableX, \n  std.ov = T, \n  estimator = 'MLM', \n  fixed.x = FALSE\n) \n\ntableXA &lt;- standardizedSolution(fit_approaches_cfa, output='data.frame') \ntableX &lt;- subset(tableXA[,c(1,2,3,8,4,9)], op == \"=~\")\n\n# EFA\nfit_approaches_efa = efa(data_tableX, 2, output = 'lavaan')\ntableXB &lt;- standardizedSolution(fit_approaches_efa, output='data.frame')\nf1 &lt;- subset(tableXB[,c(1,2,3,8,4,9)], op == \"=~\" & lhs == 'f1')[c(4:6)]\nf2 &lt;- subset(tableXB[,c(1,2,3,8,4,9)], op == \"=~\" & lhs == 'f2')[c(4:6)]\n\n# Table\ntableX_rownames &lt;- subset(tableXB, op ==\"=~\" & lhs == 'f1')$rhs\ntableX &lt;- cbind(tableX[,-c(1,2)], f1)\ntableX &lt;- cbind(tableX, f2)\ntableX &lt;- round(tableX[,-1],2)\nrownames(tableX) &lt;- tableX_rownames\ncolnames(tableX) &lt;- c(\n  \"ci.lower\",\n  \"f.cfa\",\n  \"ci.upper\",\n  \"ci.lower\",\n  \"f1.efa\",\n  \"ci.upper\",\n  \"ci.lower\",\n  \"f2.efa\",\n  \"ci.upper\"\n)\ntable2 &lt;- tableX\n\nkbl(\n  table2,\n  caption = \"Table 2. Factor loadings on the learning approach indicator items\",\n)\n\n\n\nTable 2. Factor loadings on the learning approach indicator items\n\n\nci.lower\nf.cfa\nci.upper\nci.lower\nf1.efa\nci.upper\nci.lower\nf2.efa\nci.upper\n\n\n\ndeep_1\n0.38\n0.50\n0.62\n0.39\n0.51\n0.62\n-0.11\n0.02\n0.16\n\n\ndeep_2\n0.24\n0.37\n0.50\n0.25\n0.38\n0.51\n-0.12\n0.02\n0.17\n\n\ndeep_3\n0.73\n0.82\n0.92\n0.74\n0.82\n0.91\n-0.09\n-0.02\n0.06\n\n\ndeep_4\n0.73\n0.82\n0.92\n0.73\n0.81\n0.90\n-0.06\n0.00\n0.06\n\n\nunreflective_1\n0.61\n0.75\n0.88\n-0.04\n0.01\n0.05\n0.63\n0.77\n0.90\n\n\nunreflective_2\n0.41\n0.54\n0.66\n-0.17\n-0.04\n0.09\n0.37\n0.51\n0.65\n\n\nunreflective_3\n0.43\n0.56\n0.69\n-0.13\n-0.02\n0.10\n0.40\n0.54\n0.67\n\n\nunreflective_4\n0.15\n0.28\n0.40\n0.14\n0.28\n0.42\n0.24\n0.39\n0.53"
  },
  {
    "objectID": "R-code.html#table-3-reliability-measures",
    "href": "R-code.html#table-3-reliability-measures",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 3: Reliability measures",
    "text": "Table 3: Reliability measures\n\nCronbach’s \\(\\alpha\\)\nMcDonald’s \\(\\omega\\)tot\nPerson Separation Index (PSI)\n\n\\[\nPSI = \\frac{true\\ variance}{total\\ variance} =\n1 - \\frac{mean\\ error\\ variance\\ of\\ location\\ \\theta\\ for\\ each\\ person}\n{total\\ variance\\ for\\ the\\ person\\ location\\ \\theta}\n\\]\n\nCodetable3_scales = list(\n  scale_deep,\n  scale_unreflective4,\n  scale_unreflective3, # items 1-3 only\n  scale_cynicism,\n  scale_exhaustion,\n  scale_inadequacy\n) \n\n# Cronbach's alpha\ntable3_results = list()\nfor(s in table3_scales){\n  table3_results &lt;- \n    append(table3_results, \n           psych::alpha(raw_data[s])$feldt\n    )  \n}\n\nalpha_m &lt;- matrix(data = unlist(table3_results),\n                  nrow = 6, \n                  ncol = 4,\n                  byrow = T,\n                  dimnames = list(\n                    list(\"deep\", \n                         \"unreflective4\", \n                         \"unreflective\", # items 1-3\n                         \"cynicism\",\n                         \"exhaustion\",\n                         \"inadequacy\"\n                    ),\n                    list(\"lower_ci\", \"alpha\", \"upper_ci\", \"r_bar\")\n                  )\n)\n\ntable3 &lt;- data.frame(alpha_m)[-4]  # Table 3, alpha only\n\n# McDonald's omega\nfun_omega &lt;- function(d,ind){ \n  data_boot = d[ind,]\n  fit_boot &lt;-  cfa(\n    model = m_measurement, \n    data = data_boot,\n    estimator = 'MLM',\n    std.lv=T,\n    fixed.x = FALSE)\n  o &lt;- omegaFromSem(fit = fit_boot,\n                    m = data_boot,\n                    plot = FALSE)\n  return (o$omega.tot)\n}\n\nset.seed(1234)\nbootout_omega &lt;- boot(\n  data = raw_data,\n  statistic = fun_omega,\n  R = n_iterations1 # 1000\n)\n\nci_results &lt;- boot.ci(\n  bootout_omega,\n  conf = 0.95,\n  type = 'perc'\n)\n\ntable3 &lt;- rbind(\n  table3, \n  c(ci_results$percent[4], ci_results$t0,ci_results$percent[5])\n)\nrownames(table3)[7] &lt;- \"omega.tot\"\n\n# append Person Separation Index \n# For data (N = 1948), see Schaper et al. 2023.\n# PSI = 0.86 [0.85-0.87], bootstrapped 95% confidence interval (10000 iterations)\n\ntable3 &lt;- rbind(table3, c(0.85, 0.86, 0.87))\nrownames(table3)[8] &lt;- \"pers.sep.index\"\ncolnames(table3)[2] &lt;- \"reliability_est\"\ntable3 &lt;- round(table3, 2)\n\nkbl(\n  table3,\n  caption = \"Table 3. Reliability measures\"\n) \n\n\n\nTable 3. Reliability measures\n\n\nlower_ci\nreliability_est\nupper_ci\n\n\n\ndeep\n0.66\n0.72\n0.77\n\n\nunreflective4\n0.52\n0.61\n0.68\n\n\nunreflective\n0.56\n0.64\n0.71\n\n\ncynicism\n0.76\n0.80\n0.84\n\n\nexhaustion\n0.67\n0.73\n0.78\n\n\ninadequacy\n0.42\n0.55\n0.65\n\n\nomega.tot\n0.77\n0.81\n0.84\n\n\npers.sep.index\n0.85\n0.86\n0.87"
  },
  {
    "objectID": "R-code.html#table-4-factor-loadings-from-efa-on-burnout-indicators",
    "href": "R-code.html#table-4-factor-loadings-from-efa-on-burnout-indicators",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 4: Factor loadings from EFA on burnout indicators",
    "text": "Table 4: Factor loadings from EFA on burnout indicators\n\nCodedata_table4A &lt;- raw_data[c(scale_cynicism, scale_exhaustion, scale_inadequacy)]\ndata_table4B &lt;- raw_data[c(scale_cynicism, scale_exhaustion)] \n\nburnout_loadings &lt;- data.frame(\n  efa(data_table4A, 3)$loadings, \n  efa(data_table4A, 2)$loadings,\n  rbind(\n    efa(data_table4B, 2)$loadings,\n    inadequacy_1 = NA,\n    inadequacy_2 = NA\n  )\n) \n\ncolnames(burnout_loadings) &lt;- c(\n  paste(\"dim3_f\", 1:3, sep = ''), \n  paste(\"dim2A_f\", 1:2, sep = ''),\n  paste(\"dim2B_f\", 1:2, sep = '')\n)\n\nkbl(\n  round(burnout_loadings, 2), \n  caption = \"Table 4. Factor loadings from EFA on burnout indicators\"\n) \n\n\n\nTable 4. Factor loadings from EFA on burnout indicators\n\n\ndim3_f1\ndim3_f2\ndim3_f3\ndim2A_f1\ndim2A_f2\ndim2B_f1\ndim2B_f2\n\n\n\ncynicism_1\n0.56\n0.26\n0.01\n0.50\n0.34\n0.57\n0.24\n\n\ncynicism_2\n0.88\n-0.10\n0.01\n0.76\n0.10\n0.82\n0.04\n\n\ncynicism_3\n0.89\n0.01\n-0.22\n0.86\n-0.08\n0.83\n-0.12\n\n\nexhaustion_1\n0.00\n0.66\n0.19\n0.01\n0.73\n0.13\n0.55\n\n\nexhaustion_2\n0.03\n0.01\n0.64\n0.01\n0.61\n0.03\n0.67\n\n\nexhaustion_3\n-0.08\n0.03\n0.60\n-0.12\n0.60\n-0.08\n0.61\n\n\nexhaustion_4\n0.01\n-0.12\n0.80\n-0.01\n0.61\n-0.01\n0.69\n\n\ninadequacy_1\n0.16\n0.67\n0.00\n0.16\n0.58\nNA\nNA\n\n\ninadequacy_2\n0.43\n0.21\n0.00\n0.39\n0.25\nNA\nNA"
  },
  {
    "objectID": "R-code.html#table-5a-global-fit-indices-for-the-measurement-and-full-se-models.-complete-unweighted-data.",
    "href": "R-code.html#table-5a-global-fit-indices-for-the-measurement-and-full-se-models.-complete-unweighted-data.",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 5A: Global fit indices for the measurement and full SE models. Complete unweighted data.",
    "text": "Table 5A: Global fit indices for the measurement and full SE models. Complete unweighted data.\n\nCodemy_statistic3 &lt;- function(fitted_object){\n  return(fitMeasures(fitted_object, global_fit_stats))\n}\n\n# Measurement model\n# lavaan WARNING: 1 bootstrap run resulted in a nonadmissible (n) solution.\nbootout_lavaan_measurement &lt;- bootstrapLavaan(\n  object = fit_measurement,\n  R = n_iterations1,  # 1000\n  type = 'yuan',\n  FUN = my_statistic3, \n  iseed = 1234 )\n\nWarning in bootstrapLavaan(object = fit_measurement, R = n_iterations1, :\nlavaan WARNING: 1 bootstrap run resulted in a nonadmissible (n) solution.\n\nCodedf_meas = data.frame(bootout_lavaan_measurement)\n\nci_lavaan_meas = data.frame(\n  lower_ci = numeric(),\n  higher_ci = numeric()\n)\nfor (i in 1:4){\n  ci_lavaan_meas &lt;- rbind(\n    ci_lavaan_meas,\n    quantile(df_meas[,i], c(0.025, 0.975))\n  )\n}\nci_lavaan_meas &lt;- cbind(ci_lavaan_meas, fitMeasures(fit_measurement, global_fit_stats))\ncolnames(ci_lavaan_meas) &lt;- c(\"lower_ci\", \"upper_ci\", \"estimate\")\nrownames(ci_lavaan_meas) &lt;- global_fit_stats\nci_lavaan_meas &lt;- ci_lavaan_meas[,c(1,3,2)] \n\n# Full SE model\nbootout_lavaan &lt;- bootstrapLavaan(\n  object = fit_fullSEM,\n  R = n_iterations1, # 1000\n  type = 'yuan', \n  FUN = my_statistic3, \n  iseed = 1234 )\n\ndf = data.frame(bootout_lavaan)\n\nci_lavaan = data.frame(\n  lower_ci = numeric(),\n  higher_ci = numeric()\n)\nfor (i in 1:4){\n  ci_lavaan &lt;- rbind(\n    ci_lavaan,\n    quantile(df[,i], c(0.025, 0.975))\n  )\n}\nci_lavaan &lt;- cbind(ci_lavaan, fitMeasures(fit_fullSEM, global_fit_stats))\ncolnames(ci_lavaan) &lt;- c(\"lower_ci\", \"upper_ci\", \"estimate\")\nrownames(ci_lavaan) &lt;- global_fit_stats\nci_lavaan &lt;- ci_lavaan[,c(1,3,2)] ## \n\n# combine into a single table\ntable5A &lt;- round(ci_lavaan_meas,6) \ntable5A &lt;- cbind (table5A, round(ci_lavaan,6)) \n\n\ncolnames(table5A)[4:6] &lt;- paste(' ', colnames(table5A)[4:6], sep = '')\nkbl(\n  table5A,\n  caption = \"Table 5A. Global fit indices, unweighted complete data\"\n) %&gt;%\nadd_header_above(\n  c(\" \", \"measurement model\" = 3, \"full SE model\" = 3)\n) \n\n\n\nTable 5A. Global fit indices, unweighted complete data\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeasurement model\n\n\nfull SE model\n\n\n\n\nlower_ci\nestimate\nupper_ci\nlower_ci\nestimate\nupper_ci\n\n\n\n\nrmsea.robust\n0.030546\n0.051343\n0.076442\n0.033433\n0.049237\n0.070772\n\n\ncfi.robust\n0.894980\n0.950499\n0.982705\n0.898682\n0.949762\n0.977536\n\n\ntli.scaled\n0.859026\n0.933884\n0.976861\n0.867250\n0.935051\n0.971004\n\n\nsrmr\n0.045045\n0.054436\n0.067894\n0.048997\n0.056350\n0.070598"
  },
  {
    "objectID": "R-code.html#table-5b-global-fit-indices-for-the-measurement-and-full-se-models.-weighted-data.",
    "href": "R-code.html#table-5b-global-fit-indices-for-the-measurement-and-full-se-models.-weighted-data.",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 5B: Global fit indices for the measurement and full SE models. Weighted data.",
    "text": "Table 5B: Global fit indices for the measurement and full SE models. Weighted data.\nThe following code chunks won’t run on anonymous data.\n\nCodemy_statistic3 &lt;- function(fitted_object){\n  return(fitMeasures(fitted_object, global_fit_stats))\n}\n\n# Measurement model\n# lavaan WARNING: 8 bootstrap run resulted in a nonadmissible (n) solution.\nbootout_lavaan_measurement &lt;- bootstrapLavaan(\n  object = fit_weighted_measurement,\n  R = n_iterations1, # 1000\n  type = 'yuan',\n  FUN = my_statistic3, \n  iseed = 1234 )\n\nWarning in bootstrapLavaan(object = fit_weighted_measurement, R =\nn_iterations1, : lavaan WARNING: 8 bootstrap runs resulted in nonadmissible (n)\nsolutions.\n\nCodedf_meas = data.frame(bootout_lavaan_measurement)\n\nci_lavaan_meas = data.frame(\n  lower_ci = numeric(),\n  higher_ci = numeric()\n)\nfor (i in 1:4){\n  ci_lavaan_meas &lt;- rbind(\n    ci_lavaan_meas,\n    quantile(df_meas[,i], c(0.025, 0.975))\n  )\n}\nci_lavaan_meas &lt;- cbind(\n  ci_lavaan_meas, \n  fitMeasures(fit_weighted_measurement, global_fit_stats)\n)\ncolnames(ci_lavaan_meas) &lt;- c(\"lower_ci\", \"upper_ci\", \"estimate\")\nrownames(ci_lavaan_meas) &lt;- global_fit_stats\nci_lavaan_meas &lt;- ci_lavaan_meas[,c(1,3,2)] \n\n# Full SE model\n# lavaan WARNING: 7 bootstrap run resulted in a nonadmissible (n) solution.\nbootout_lavaan &lt;- bootstrapLavaan(\n  object = fit_weighted_fullSEM,\n  R = n_iterations1, # 1000\n  type = 'yuan', \n  FUN = my_statistic3, \n  iseed = 1234 )\n\nWarning in bootstrapLavaan(object = fit_weighted_fullSEM, R = n_iterations1, :\nlavaan WARNING: 7 bootstrap runs resulted in nonadmissible (n) solutions.\n\nCodedf = data.frame(bootout_lavaan)\n\nci_lavaan = data.frame(\n  lower_ci = numeric(),\n  higher_ci = numeric()\n)\nfor (i in 1:4){\n  ci_lavaan &lt;- rbind(\n    ci_lavaan,\n    quantile(df[,i], c(0.025, 0.975))\n  )\n}\nci_lavaan &lt;- cbind(ci_lavaan, fitMeasures(fit_weighted_fullSEM, global_fit_stats))\ncolnames(ci_lavaan) &lt;- c(\"lower_ci\", \"upper_ci\", \"estimate\")\nrownames(ci_lavaan) &lt;- global_fit_stats\nci_lavaan &lt;- ci_lavaan[,c(1,3,2)] \n\n# combine into a single table\ntable5B &lt;- round(ci_lavaan_meas,6) \ntable5B &lt;- cbind (table5B, round(ci_lavaan,6))\n\ncolnames(table5B) &lt;- colnames(table5A)\n\nkbl(\n  table5B,\n  caption = \"Table 5B. Global fit indices, weighted data.\"\n) %&gt;%\nadd_header_above(\n  c(\" \", \"measurement model\" = 3, \"full SE model\" = 3)\n)\n\n\n\nTable 5B. Global fit indices, weighted data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeasurement model\n\n\nfull SE model\n\n\n\n\nlower_ci\nestimate\nupper_ci\nlower_ci\nestimate\nupper_ci\n\n\n\n\nrmsea.robust\n0.042512\n0.059563\n0.092646\n0.037545\n0.050652\n0.083275\n\n\ncfi.robust\n0.855572\n0.938584\n0.970613\n0.868338\n0.948213\n0.972305\n\n\ntli.scaled\n0.812743\n0.921334\n0.961989\n0.830231\n0.934322\n0.964288\n\n\nsrmr\n0.049758\n0.059491\n0.080001\n0.051986\n0.058919\n0.079079"
  },
  {
    "objectID": "R-code.html#table-5c-global-fit-indices-down-sampled-data",
    "href": "R-code.html#table-5c-global-fit-indices-down-sampled-data",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 5C: Global fit indices, down-sampled data",
    "text": "Table 5C: Global fit indices, down-sampled data\nThe following code chunk won’t run on anonymous data.\n\nCode# measurement model\nindices &lt;- downsampled_data_fit_indices[[1]]\nfor (i in 2:n_iterations){\n  indices &lt;- cbind(indices, downsampled_data_fit_indices[[i]])\n}\ncolnames(indices) &lt;- 1:n_iterations\n\ntable5Cmeas &lt;- apply(indices, 1, quantile, c(0.025, 0.975))\ntable5Cmeas &lt;- rbind(means = table5Cmeas, apply(indices, 1, mean))[c(3,1,2),]\nrownames(table5Cmeas)[1] &lt;- \"mean\"\n\n# full SEM\nindices &lt;- downsampled_data_fit_indices_fullSEM[[1]]\nfor (i in 2:n_iterations){\n  indices &lt;- cbind(indices, downsampled_data_fit_indices_fullSEM[[i]])\n}\ncolnames(indices) &lt;- 1:n_iterations\ntable5CfullSEM &lt;- apply(indices, 1, quantile, c(0.025, 0.975))\ntable5CfullSEM &lt;- rbind(table5CfullSEM, apply(indices, 1, mean))[c(3,1,2),]\nrownames(table5CfullSEM)[1] &lt;- \"mean\"\n\n# combine into a single table\ntable5C &lt;- data.frame(cbind(t(table5Cmeas), t(table5CfullSEM)))[c(2,1,3,5,4,6)]\ncolnames(table5C) &lt;- colnames(table5A)\n\nkbl(\n  table5C,\n  caption = \"Table 5C. Global fit indices, down-sampled data, 1000 iterations.\"\n) %&gt;%\nadd_header_above(\n  c(\" \", \"measurement model\" = 3, \"full SE model\" = 3)\n) \n\n\n\nTable 5C. Global fit indices, down-sampled data, 1000 iterations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeasurement model\n\n\nfull SE model\n\n\n\n\nlower_ci\nestimate\nupper_ci\nlower_ci\nestimate\nupper_ci\n\n\n\n\nrmsea.robust\n0.0374997\n0.0501804\n0.0623035\n0.0293632\n0.0433377\n0.0561114\n\n\ncfi.robust\n0.9296487\n0.9530494\n0.9745723\n0.9349271\n0.9592552\n0.9818047\n\n\ntli.scaled\n0.9041417\n0.9361820\n0.9649276\n0.9138940\n0.9464964\n0.9756501\n\n\nsrmr\n0.0571531\n0.0623561\n0.0681436\n0.0574568\n0.0627865\n0.0684916"
  },
  {
    "objectID": "R-code.html#table-6a-measurement-invariance-between-study-years",
    "href": "R-code.html#table-6a-measurement-invariance-between-study-years",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 6A: Measurement invariance between study years",
    "text": "Table 6A: Measurement invariance between study years\n\nCode# measurement invariance, study year\nset.seed(1234)\nfit_constrained_syear &lt;- sem(\n  model = m_constrained_syear,\n  data &lt;- raw_data,\n  std.ov = T,\n  estimator = \"MLM\", \n  fixed.x = 'default'\n)\n\nset.seed(1234)\nfit_unconstrained_syear &lt;- sem(\n  model = m_unconstrained_syear,\n  data &lt;- raw_data,\n  std.ov = T,\n  estimator = \"MLM\", \n  fixed.x = 'default'\n)\n\ntable6A &lt;- lavTestLRT(\n  fit_unconstrained_syear, \n  fit_constrained_syear\n) # deltaChisq = 3.781 not 4.058\n\ndelta_chiq &lt;- table6A[2, 'Chisq'] - table6A[1, 'Chisq']\npval &lt;- pchisq(delta_chiq, 4, lower.tail = F)\ntable6A[2, 'Chisq diff'] &lt;- delta_chiq\ntable6A[2, 'Pr(&gt;Chisq)'] &lt;- pval\n\nkbl(\n  table6A, \n  caption=\"Table 6A. Measurement invariance between study years\"\n)\n\n\n\nTable 6A. Measurement invariance between study years\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nDf diff\nPr(&gt;Chisq)\n\n\n\nfit_unconstrained_syear\n93\n7359.247\n7506.811\n166.6358\nNA\nNA\nNA\n\n\nfit_constrained_syear\n97\n7355.028\n7488.539\n170.4167\n3.780879\n4\n0.436472\n\n\n\n\n\n\n\nCode# delta-cfi\nfitMeasures(fit_constrained_syear,'cfi.robust' ) -\n  fitMeasures(fit_unconstrained_syear, 'cfi.robust')\n\ncfi.robust \n         0"
  },
  {
    "objectID": "R-code.html#table-6b-measurement-invariance-between-genders",
    "href": "R-code.html#table-6b-measurement-invariance-between-genders",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table 6B: Measurement invariance between genders",
    "text": "Table 6B: Measurement invariance between genders\nThe following code chunks won’t run on anonymous data.\n\nCode# remove 2 students of gender 'other'\ndata6B &lt;- subset(raw_data, gender !=3)\ndata6B$gender &lt;- data6B$gender - 1\ntable(data6B$gender)\n\n\n  0   1 \n 29 217 \n\nCodeset.seed(1234)\nfit_constrained_gender &lt;- sem(\n  model = m_constrained_gender,\n  data &lt;- data6B,\n  std.ov = T,\n  estimator = \"MLM\",\n  fixed.x = 'default'\n)\n\nset.seed(1234)\nfit_unconstrained_gender &lt;- sem(\n  model = m_unconstrained_gender,\n  data &lt;- data6B,\n  std.ov = T,\n  estimator = \"MLM\",\n  fixed.x = 'default'\n)\n\n# chisq-difference test\ntable6B &lt;- lavTestLRT(\n  fit_constrained_gender,\n  fit_unconstrained_gender\n) # deltaChisq = 19.350 not 18.612\n\ndelta_chiq &lt;- table6B[2, 'Chisq'] - table6B[1, 'Chisq']\npval &lt;- pchisq(delta_chiq, 4, lower.tail = F)\ntable6B[2, 'Chisq diff'] &lt;- delta_chiq\ntable6B[2, 'Pr(&gt;Chisq)'] &lt;- pval\n\n\nkbl(\n  table6B,\n  caption = \"Table 6B. Chi-squared difference test on MI between genders\"\n)\n\n\n\nTable 6B. Chi-squared difference test on MI between genders\n\n\nDf\nAIC\nBIC\nChisq\nChisq diff\nDf diff\nPr(&gt;Chisq)\n\n\n\nfit_unconstrained_gender\n108\n6592.741\n6739.965\n178.7771\nNA\nNA\nNA\n\n\nfit_constrained_gender\n112\n6604.091\n6737.293\n198.1272\n19.35008\n4\n0.0006707\n\n\n\n\n\n\n\nCode# delta-cfi\nfitMeasures(fit_constrained_gender,'cfi.robust' ) -\n  fitMeasures(fit_unconstrained_gender, 'cfi.robust')\n\ncfi.robust \n    -0.013"
  },
  {
    "objectID": "R-code.html#table-s2a-bivariate-spearman-correlations-between-indicator-items",
    "href": "R-code.html#table-s2a-bivariate-spearman-correlations-between-indicator-items",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S2A: Bivariate Spearman correlations between indicator items",
    "text": "Table S2A: Bivariate Spearman correlations between indicator items\n\nCodedata_stable2 &lt;- raw_data[, c(\n  grep (\"deep\", colnames(raw_data)),\n  grep ('unreflective[_4]', colnames(raw_data)),\n  \n  # corr btw burnout and unrefl_1-3 sum scores is 0.47\n  # grep ('unreflective[_123]*[^_4]', colnames(raw_data)),\n  \n  grep (\"cynicism\", colnames(raw_data)),\n  grep (\"exhaustion\", colnames(raw_data)),\n  grep (\"inadequacy\", colnames(raw_data)),\n  grep (\"burnout\", colnames(raw_data)))]\n\nset.seed(1234)\ncci &lt;- cor.ci(\n  data_stable2,\n  n.iter = n_iterations1, # 1000\n  method = 'sp',\n  show.legend = FALSE,\n  plot = FALSE\n)\n\n\n\nCodecorPlot(# table S2A\n  main = '',\n  adjust = T, \n  pval = T, \n  cci$rho, \n  show.legend = FALSE, \n  xlas = 2,\n  MAR = 5, \n  keep.par = TRUE\n) \n\n\n\nTable S2A. Interitem correlation coefficients"
  },
  {
    "objectID": "R-code.html#table-s2b.-confidence-intervals-of-the-interitem-correlation-coefficients-1000-bootstrap-iterations.",
    "href": "R-code.html#table-s2b.-confidence-intervals-of-the-interitem-correlation-coefficients-1000-bootstrap-iterations.",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S2B. Confidence intervals of the interitem correlation coefficients (1000 bootstrap iterations).",
    "text": "Table S2B. Confidence intervals of the interitem correlation coefficients (1000 bootstrap iterations).\n\nCodecorPlotUpperLowerCi( # table S2B\n  R = cci, \n  numbers = TRUE, \n  show.legend = FALSE,\n  main = '',\n  xlas = 2,\n  MAR = 5,\n  keep.par = TRUE\n) \n\n\n\nTable S2B. Confidence intervals for interitem correlation coefficients"
  },
  {
    "objectID": "R-code.html#table-s3-testing-for-normality.",
    "href": "R-code.html#table-s3-testing-for-normality.",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S3: Testing for normality.",
    "text": "Table S3: Testing for normality.\n\nTable S3A: VetRepos test score\nTable S3B: scales\n\nDeep sampling for kurtosis bootstrapping requires setting SAMPLING_DEPTH accordingly if an accurate estimate of the p-value is desirable. This may push the resources of a personal computer. CI_VALUE may also need to be adjusted.\n\nCode# for an accurate p-value estimation, depending on your computer resources:\nSAMPLING_DEPTH = 2000 # change to desired depth, e.g. 10^7, or more\nCI_VALUE = 0.95 # decrease e.g to 0.9 or 0.8 \n\n### Table S3A: normality of vetrepos score\n\n# Shapiro-Wilk test fails on the VetRepos test score\nshapiro.test(raw_data$vetrepos_score)\n\n\n    Shapiro-Wilk normality test\n\ndata:  raw_data$vetrepos_score\nW = 0.98552, p-value = 0.01292\n\nCode# bootstrapped kurtosis (VetRepos test score)\nfun_kurtosis &lt;- function(d,ind){ \n  return (kurtosi(d[ind,]))\n}\n\nset.seed(1234)\nbootout_kurtosis &lt;- boot(\n  data = raw_data['vetrepos_score'],\n  statistic = fun_kurtosis, \n  R = SAMPLING_DEPTH \n)\n\nn = length(which(sort(bootout_kurtosis$t) &gt;= 0)) \np_kurtosis = (2*n)/bootout_kurtosis$R \n\nci_kurtosis &lt;- boot.ci(\n  bootout_kurtosis,\n  conf = CI_VALUE,\n  type = 'perc'\n)\n\nvetrepos_kurtosis &lt;- c(\n  ci_kurtosis$percent[4], \n  ci_kurtosis$t0, \n  ci_kurtosis$percent[5], \n  p_kurtosis\n) \n\n# bootstrapped skewness (VetRepos test score)\nfun_skewness &lt;- function(d,ind){ \n  return(skew(d[ind])['skew (g1)'])\n}\n\nset.seed(1234)\nbootout_skewness &lt;- boot(\n  data = raw_data$vetrepos_score,\n  statistic = fun_skewness, \n  R = 2000\n)\n\np_skew = 2*(1-(length(which(sort(bootout_skewness$t) &gt;= 0)))/2000) \n\nci_skewness &lt;- boot.ci(\n  bootout_skewness,\n  conf = 0.95,\n  type = 'perc'\n)\n\nvetrepos_skewness &lt;- c(\n  ci_skewness$percent[4],   \n  ci_skewness$t0,  \n  ci_skewness$percent[5],  \n  p_skew\n)\n\nSTable3A &lt;- data.frame(\n  lower_ci = numeric(),\n  estimate = numeric(),\n  upper_ci = numeric(),\n  pvalue = numeric()\n)\n\nSTable3A &lt;-rbind(\n  rbind(STable3A,vetrepos_skewness),\n  vetrepos_kurtosis\n)\ncolnames(STable3A) &lt;- c('lower_ci', 'estimate', 'upper_ci', \"pvalue\")\nrownames(STable3A) &lt;- c('skewness', 'kurtosis')\n\nkbl(\n  STable3A,\n  caption = \"Table S3A. Kurtosis and skewness of the VetRepos score\",\n) \n\n\n\nTable S3A. Kurtosis and skewness of the VetRepos score\n\n\nlower_ci\nestimate\nupper_ci\npvalue\n\n\n\nskewness\n-0.1521057\n0.0301417\n0.1993484\n0.745\n\n\nkurtosis\n-0.9787786\n-0.7477947\n-0.4840059\n0.000\n\n\n\n\n\n\n\nCode### Table S3B: normality of the scales\n\n# Mardia's test on the scales, requires semTools\nmardia_list &lt;- list()\nfor (\n  s in c(\n    list(scale_all),\n    list(scale_deep),\n    list(scale_unreflective4),\n    list(scale_unreflective3),\n    list(scale_cynicism),\n    list(scale_exhaustion),\n    list(scale_inadequacy)\n  )\n){\n  estimates &lt;- c(mardiaKurtosis(raw_data[,c(s)]), mardiaSkew(raw_data[,c(s)]))\n  mardia_list &lt;- append(mardia_list, estimates)\n}\n\nmatrix_mardia &lt;- matrix(\n  data=unlist(mardia_list), nrow=7, ncol=7, byrow = T, \n  dimnames = c(\n    list(\n      c(\n        \"all_scales\", \n        \"deep_approach\",\n        \"unreflective_approach4\",\n        \"unreflective_approach3\",\n        \"cynicism\",\n        \"exhaustion\",\n        \"inadequacy\"\n      )\n    ),\n    list(c('b2d', 'z', 'p2', 'b1d', 'chi', 'df', 'p1'))\n  )\n)\n\nstable3B &lt;- data.frame(matrix_mardia)\n\nkbl(\n  stable3B,\n  caption = \"Table S3B. Mardia's multivariate normality test on the scales\",\n) \n\n\n\nTable S3B. Mardia's multivariate normality test on the scales\n\n\nb2d\nz\np2\nb1d\nchi\ndf\np1\n\n\n\nall_scales\n344.915837\n6.7894979\n0.0000000\n36.0018973\n1488.078423\n969\n0.0000000\n\n\ndeep_approach\n27.282787\n3.7309365\n0.0001908\n2.1548234\n89.066035\n20\n0.0000000\n\n\nunreflective_approach4\n24.136013\n0.1545809\n0.8771517\n1.8033408\n74.538088\n20\n0.0000000\n\n\nunreflective_approach3\n14.247097\n-1.0823660\n0.2790899\n0.7139070\n29.508155\n10\n0.0010305\n\n\ncynicism\n16.299374\n1.8679680\n0.0617665\n2.0099971\n83.079880\n10\n0.0000000\n\n\nexhaustion\n22.819720\n-1.3414059\n0.1797887\n1.1498543\n47.527309\n20\n0.0004954\n\n\ninadequacy\n6.765118\n-2.4308677\n0.0150627\n0.0319093\n1.318918\n4\n0.8581577"
  },
  {
    "objectID": "R-code.html#table-s4-measurement-model-standardized-parameters",
    "href": "R-code.html#table-s4-measurement-model-standardized-parameters",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S4: Measurement model, standardized parameters",
    "text": "Table S4: Measurement model, standardized parameters\n\nTable S4A: unweighted complete data\nTable S4B: weighted data (This code won’t run on the anonymous data.)\n\n\nCode# Table S4A\nSTable4A &lt;- standardizedSolution(fit_measurement, output = 'data.frame') \nSTable4A$h2 = NA\n\nSTable4A [STable4A$op == \"=~\", \"h2\"] &lt;- STable4A [STable4A$op == \"=~\", \"est.std\"]^2\n\nSTable4A &lt;- cbind(\n  STable4A[1:3],\n  round(STable4A[4:ncol(STable4A)], 2)\n)\n\nkbl(\n  STable4A,\n  caption = \"Table S4A. Parameter estimates from the measurement model fitted on the unweighted data\"\n) \n\n\n\nTable S4A. Parameter estimates from the measurement model fitted on the unweighted data\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\nh2\n\n\n\nf_deep\n=~\ndeep_1\n0.50\n0.06\n8.40\n0.00\n0.38\n0.61\n0.25\n\n\nf_deep\n=~\ndeep_2\n0.38\n0.07\n5.63\n0.00\n0.25\n0.51\n0.14\n\n\nf_deep\n=~\ndeep_3\n0.82\n0.05\n17.03\n0.00\n0.73\n0.92\n0.68\n\n\nf_deep\n=~\ndeep_4\n0.82\n0.05\n17.07\n0.00\n0.73\n0.92\n0.68\n\n\nf_unreflective\n=~\nunreflective_1\n0.63\n0.06\n11.10\n0.00\n0.52\n0.74\n0.40\n\n\nf_unreflective\n=~\nunreflective_2\n0.53\n0.07\n8.00\n0.00\n0.40\n0.66\n0.28\n\n\nf_unreflective\n=~\nunreflective_3\n0.68\n0.06\n11.67\n0.00\n0.56\n0.79\n0.46\n\n\nf_cynicism\n=~\ncynicism_1\n0.70\n0.05\n15.54\n0.00\n0.61\n0.79\n0.49\n\n\nf_cynicism\n=~\ncynicism_2\n0.86\n0.04\n23.65\n0.00\n0.79\n0.93\n0.74\n\n\nf_cynicism\n=~\ncynicism_3\n0.73\n0.04\n18.10\n0.00\n0.65\n0.81\n0.54\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.64\n0.05\n13.26\n0.00\n0.55\n0.74\n0.41\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.68\n0.05\n12.69\n0.00\n0.57\n0.78\n0.46\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.52\n0.06\n8.76\n0.00\n0.41\n0.64\n0.28\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.69\n0.05\n14.68\n0.00\n0.60\n0.78\n0.48\n\n\ndeep_1\n~~\ndeep_1\n0.75\n0.06\n12.76\n0.00\n0.64\n0.87\nNA\n\n\ndeep_2\n~~\ndeep_2\n0.86\n0.05\n17.02\n0.00\n0.76\n0.96\nNA\n\n\ndeep_3\n~~\ndeep_3\n0.32\n0.08\n4.08\n0.00\n0.17\n0.48\nNA\n\n\ndeep_4\n~~\ndeep_4\n0.32\n0.08\n4.11\n0.00\n0.17\n0.48\nNA\n\n\nunreflective_1\n~~\nunreflective_1\n0.60\n0.07\n8.46\n0.00\n0.46\n0.74\nNA\n\n\nunreflective_2\n~~\nunreflective_2\n0.72\n0.07\n10.25\n0.00\n0.58\n0.86\nNA\n\n\nunreflective_3\n~~\nunreflective_3\n0.54\n0.08\n6.95\n0.00\n0.39\n0.70\nNA\n\n\ncynicism_1\n~~\ncynicism_1\n0.51\n0.06\n8.11\n0.00\n0.39\n0.63\nNA\n\n\ncynicism_2\n~~\ncynicism_2\n0.26\n0.06\n4.25\n0.00\n0.14\n0.39\nNA\n\n\ncynicism_3\n~~\ncynicism_3\n0.46\n0.06\n7.72\n0.00\n0.34\n0.58\nNA\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.59\n0.06\n9.47\n0.00\n0.47\n0.71\nNA\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.54\n0.07\n7.54\n0.00\n0.40\n0.68\nNA\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.72\n0.06\n11.52\n0.00\n0.60\n0.85\nNA\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.52\n0.07\n7.98\n0.00\n0.39\n0.65\nNA\n\n\nf_deep\n~~\nf_deep\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_deep\n~~\nf_unreflective\n-0.29\n0.08\n-3.54\n0.00\n-0.46\n-0.13\nNA\n\n\nf_deep\n~~\nf_cynicism\n-0.19\n0.09\n-2.07\n0.04\n-0.37\n-0.01\nNA\n\n\nf_deep\n~~\nf_exhaustion\n0.08\n0.08\n1.09\n0.28\n-0.07\n0.23\nNA\n\n\nf_unreflective\n~~\nf_cynicism\n0.55\n0.08\n6.73\n0.00\n0.39\n0.71\nNA\n\n\nf_unreflective\n~~\nf_exhaustion\n0.63\n0.07\n8.53\n0.00\n0.49\n0.78\nNA\n\n\nf_cynicism\n~~\nf_exhaustion\n0.54\n0.06\n8.42\n0.00\n0.41\n0.66\nNA\n\n\n\n\n\n\nThe following code chunk won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\n# Table S4B\nSTable4B &lt;- standardizedSolution(fit_weighted_measurement, output = 'data.frame') \n\nSTable4B$h2 = NA\n\nSTable4B [STable4B$op == \"=~\", \"h2\"] &lt;- STable4B [STable4B$op == \"=~\", \"est.std\"]^2\n\nSTable4B &lt;- cbind(\n  STable4B[1:3],\n  round(STable4B[4:ncol(STable4B)], 2)\n)\n\nkbl(\n  STable4B,\n  caption = \"Table S4B. Parameter estimates from the measurement model fitted on the weighted data\"\n)\n\n\n\nTable S4B. Parameter estimates from the measurement model fitted on the weighted data\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\nh2\n\n\n\nf_deep\n=~\ndeep_1\n0.48\n0.06\n7.54\n0.00\n0.35\n0.60\n0.23\n\n\nf_deep\n=~\ndeep_2\n0.34\n0.07\n4.99\n0.00\n0.21\n0.48\n0.12\n\n\nf_deep\n=~\ndeep_3\n0.89\n0.05\n16.46\n0.00\n0.78\n0.99\n0.79\n\n\nf_deep\n=~\ndeep_4\n0.79\n0.05\n15.34\n0.00\n0.69\n0.89\n0.63\n\n\nf_unreflective\n=~\nunreflective_1\n0.62\n0.06\n10.90\n0.00\n0.51\n0.73\n0.39\n\n\nf_unreflective\n=~\nunreflective_2\n0.51\n0.07\n7.67\n0.00\n0.38\n0.64\n0.26\n\n\nf_unreflective\n=~\nunreflective_3\n0.68\n0.06\n11.28\n0.00\n0.56\n0.79\n0.46\n\n\nf_cynicism\n=~\ncynicism_1\n0.70\n0.04\n15.87\n0.00\n0.62\n0.79\n0.49\n\n\nf_cynicism\n=~\ncynicism_2\n0.88\n0.04\n24.13\n0.00\n0.81\n0.96\n0.78\n\n\nf_cynicism\n=~\ncynicism_3\n0.76\n0.04\n18.66\n0.00\n0.68\n0.84\n0.58\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.65\n0.05\n13.91\n0.00\n0.56\n0.74\n0.42\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.68\n0.05\n13.54\n0.00\n0.58\n0.77\n0.46\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.56\n0.06\n10.13\n0.00\n0.45\n0.67\n0.31\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.74\n0.04\n16.63\n0.00\n0.66\n0.83\n0.55\n\n\ndeep_1\n~~\ndeep_1\n0.77\n0.06\n12.72\n0.00\n0.65\n0.89\nNA\n\n\ndeep_2\n~~\ndeep_2\n0.88\n0.05\n18.63\n0.00\n0.79\n0.97\nNA\n\n\ndeep_3\n~~\ndeep_3\n0.21\n0.10\n2.21\n0.03\n0.02\n0.40\nNA\n\n\ndeep_4\n~~\ndeep_4\n0.37\n0.08\n4.58\n0.00\n0.21\n0.53\nNA\n\n\nunreflective_1\n~~\nunreflective_1\n0.61\n0.07\n8.60\n0.00\n0.47\n0.75\nNA\n\n\nunreflective_2\n~~\nunreflective_2\n0.74\n0.07\n10.73\n0.00\n0.60\n0.87\nNA\n\n\nunreflective_3\n~~\nunreflective_3\n0.54\n0.08\n6.69\n0.00\n0.38\n0.70\nNA\n\n\ncynicism_1\n~~\ncynicism_1\n0.51\n0.06\n8.15\n0.00\n0.38\n0.63\nNA\n\n\ncynicism_2\n~~\ncynicism_2\n0.22\n0.06\n3.37\n0.00\n0.09\n0.35\nNA\n\n\ncynicism_3\n~~\ncynicism_3\n0.42\n0.06\n6.79\n0.00\n0.30\n0.54\nNA\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.58\n0.06\n9.66\n0.00\n0.46\n0.70\nNA\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.54\n0.07\n8.01\n0.00\n0.41\n0.67\nNA\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.69\n0.06\n11.19\n0.00\n0.57\n0.81\nNA\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.45\n0.07\n6.75\n0.00\n0.32\n0.58\nNA\n\n\nf_deep\n~~\nf_deep\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_deep\n~~\nf_unreflective\n-0.18\n0.09\n-2.11\n0.03\n-0.35\n-0.01\nNA\n\n\nf_deep\n~~\nf_cynicism\n-0.13\n0.09\n-1.45\n0.15\n-0.30\n0.05\nNA\n\n\nf_deep\n~~\nf_exhaustion\n0.14\n0.07\n1.93\n0.05\n0.00\n0.28\nNA\n\n\nf_unreflective\n~~\nf_cynicism\n0.52\n0.08\n6.34\n0.00\n0.36\n0.68\nNA\n\n\nf_unreflective\n~~\nf_exhaustion\n0.64\n0.07\n9.07\n0.00\n0.50\n0.78\nNA\n\n\nf_cynicism\n~~\nf_exhaustion\n0.52\n0.06\n8.59\n0.00\n0.40\n0.64\nNA"
  },
  {
    "objectID": "R-code.html#table-s5-interitem-residual-correlation-coefficients-fitted-full-model",
    "href": "R-code.html#table-s5-interitem-residual-correlation-coefficients-fitted-full-model",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S5: Interitem residual correlation coefficients, fitted full model",
    "text": "Table S5: Interitem residual correlation coefficients, fitted full model\n\nCode# Table S5A unweighted complete data\nSTable5A &lt;- lavResiduals(fit_fullSEM, type = 'cor')$cov\nrange(STable5A)\n\n[1] -0.1493163  0.2276201\n\nCodekbl(\n  round(STable5A,3),\n  caption = \"Table S5A. Standardized residual correlations. Full SEM.\",\n) \n\n\n\nTable S5A. Standardized residual correlations. Full SEM.\n\n\ndeep_1\ndeep_2\ndeep_3\ndeep_4\nunreflective_1\nunreflective_2\nunreflective_3\ncynicism_1\ncynicism_2\ncynicism_3\nexhaustion_1\nexhaustion_2\nexhaustion_3\nexhaustion_4\nscore_div100\nstudy_year\n\n\n\ndeep_1\n0.000\n0.153\n-0.003\n-0.018\n0.002\n-0.035\n0.050\n-0.008\n-0.058\n0.009\n-0.102\n-0.032\n0.055\n-0.016\n0.049\n0.090\n\n\ndeep_2\n0.153\n0.000\n-0.044\n0.013\n0.027\n0.047\n-0.072\n-0.030\n-0.006\n-0.014\n-0.044\n0.049\n0.033\n0.017\n-0.071\n-0.035\n\n\ndeep_3\n-0.003\n-0.044\n0.000\n0.005\n-0.042\n-0.010\n0.032\n0.055\n0.013\n-0.011\n-0.028\n-0.047\n0.130\n0.014\n0.066\n0.069\n\n\ndeep_4\n-0.018\n0.013\n0.005\n0.000\n-0.016\n-0.039\n0.040\n0.010\n-0.027\n0.014\n-0.011\n-0.065\n0.111\n0.009\n0.052\n0.106\n\n\nunreflective_1\n0.002\n0.027\n-0.042\n-0.016\n0.000\n0.042\n-0.006\n0.028\n-0.103\n-0.067\n0.108\n-0.014\n-0.095\n0.008\n-0.034\n-0.075\n\n\nunreflective_2\n-0.035\n0.047\n-0.010\n-0.039\n0.042\n0.000\n-0.027\n0.019\n0.004\n0.080\n0.002\n-0.097\n-0.117\n0.013\n0.000\n0.033\n\n\nunreflective_3\n0.050\n-0.072\n0.032\n0.040\n-0.006\n-0.027\n0.000\n0.061\n0.048\n-0.010\n0.107\n0.037\n-0.098\n-0.012\n-0.018\n-0.035\n\n\ncynicism_1\n-0.008\n-0.030\n0.055\n0.010\n0.028\n0.019\n0.061\n0.000\n-0.016\n-0.019\n0.228\n0.092\n0.019\n0.055\n0.022\n0.017\n\n\ncynicism_2\n-0.058\n-0.006\n0.013\n-0.027\n-0.103\n0.004\n0.048\n-0.016\n0.000\n0.022\n0.018\n-0.020\n-0.011\n-0.027\n0.084\n0.080\n\n\ncynicism_3\n0.009\n-0.014\n-0.011\n0.014\n-0.067\n0.080\n-0.010\n-0.019\n0.022\n0.000\n-0.030\n-0.033\n-0.149\n-0.081\n-0.061\n0.005\n\n\nexhaustion_1\n-0.102\n-0.044\n-0.028\n-0.011\n0.108\n0.002\n0.107\n0.228\n0.018\n-0.030\n0.000\n-0.013\n-0.023\n-0.049\n0.095\n0.124\n\n\nexhaustion_2\n-0.032\n0.049\n-0.047\n-0.065\n-0.014\n-0.097\n0.037\n0.092\n-0.020\n-0.033\n-0.013\n0.000\n0.023\n0.024\n-0.070\n-0.057\n\n\nexhaustion_3\n0.055\n0.033\n0.130\n0.111\n-0.095\n-0.117\n-0.098\n0.019\n-0.011\n-0.149\n-0.023\n0.023\n0.000\n0.050\n0.109\n0.078\n\n\nexhaustion_4\n-0.016\n0.017\n0.014\n0.009\n0.008\n0.013\n-0.012\n0.055\n-0.027\n-0.081\n-0.049\n0.024\n0.050\n0.000\n-0.007\n0.004\n\n\nscore_div100\n0.049\n-0.071\n0.066\n0.052\n-0.034\n0.000\n-0.018\n0.022\n0.084\n-0.061\n0.095\n-0.070\n0.109\n-0.007\n0.000\n0.012\n\n\nstudy_year\n0.090\n-0.035\n0.069\n0.106\n-0.075\n0.033\n-0.035\n0.017\n0.080\n0.005\n0.124\n-0.057\n0.078\n0.004\n0.012\n0.000\n\n\n\n\n\n\nThe following code chunks won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\n\n# Table S5B weighted data\nSTable5B &lt;- lavResiduals(fit_weighted_fullSEM, type = 'cor')$cov\nrange(STable5B)\n\n[1] -0.1373657  0.2563980\n\nCodekbl(\n  round(STable5B,3),\n  caption = \"Table S5B. Standardized residual correlations. Full SEM, weighted data.\",\n) \n\n\n\nTable S5B. Standardized residual correlations. Full SEM, weighted data.\n\n\ndeep_1\ndeep_2\ndeep_3\ndeep_4\nunreflective_1\nunreflective_2\nunreflective_3\ncynicism_1\ncynicism_2\ncynicism_3\nexhaustion_1\nexhaustion_2\nexhaustion_3\nexhaustion_4\nscore_div100\nstudy_year\n\n\n\ndeep_1\n0.000\n0.166\n-0.003\n-0.014\n-0.069\n-0.024\n0.074\n0.013\n-0.026\n0.024\n-0.086\n-0.094\n-0.019\n-0.022\n0.025\n0.041\n\n\ndeep_2\n0.166\n0.000\n-0.024\n0.016\n-0.010\n0.084\n-0.035\n-0.021\n0.021\n-0.023\n-0.062\n-0.029\n-0.030\n0.007\n-0.053\n-0.004\n\n\ndeep_3\n-0.003\n-0.024\n0.000\n0.002\n-0.104\n-0.060\n0.095\n0.022\n0.008\n-0.016\n-0.021\n-0.066\n0.047\n0.060\n-0.018\n-0.046\n\n\ndeep_4\n-0.014\n0.016\n0.002\n0.000\n-0.072\n-0.036\n0.129\n0.009\n-0.027\n0.016\n-0.008\n-0.069\n0.027\n0.064\n-0.009\n0.009\n\n\nunreflective_1\n-0.069\n-0.010\n-0.104\n-0.072\n0.000\n0.026\n-0.009\n0.034\n-0.103\n-0.092\n0.102\n-0.010\n-0.137\n0.008\n-0.025\n-0.031\n\n\nunreflective_2\n-0.024\n0.084\n-0.060\n-0.036\n0.026\n0.000\n-0.009\n0.042\n0.027\n0.052\n-0.019\n-0.131\n-0.109\n0.006\n0.013\n0.059\n\n\nunreflective_3\n0.074\n-0.035\n0.095\n0.129\n-0.009\n-0.009\n0.000\n0.090\n0.049\n-0.021\n0.141\n0.034\n-0.054\n-0.006\n0.046\n0.043\n\n\ncynicism_1\n0.013\n-0.021\n0.022\n0.009\n0.034\n0.042\n0.090\n0.000\n-0.016\n-0.011\n0.256\n0.076\n0.032\n0.040\n0.068\n0.083\n\n\ncynicism_2\n-0.026\n0.021\n0.008\n-0.027\n-0.103\n0.027\n0.049\n-0.016\n0.000\n0.016\n0.040\n-0.006\n-0.014\n-0.036\n0.109\n0.128\n\n\ncynicism_3\n0.024\n-0.023\n-0.016\n0.016\n-0.092\n0.052\n-0.021\n-0.011\n0.016\n0.000\n-0.038\n-0.019\n-0.130\n-0.072\n-0.009\n0.090\n\n\nexhaustion_1\n-0.086\n-0.062\n-0.021\n-0.008\n0.102\n-0.019\n0.141\n0.256\n0.040\n-0.038\n0.000\n-0.001\n-0.031\n-0.053\n0.098\n0.123\n\n\nexhaustion_2\n-0.094\n-0.029\n-0.066\n-0.069\n-0.010\n-0.131\n0.034\n0.076\n-0.006\n-0.019\n-0.001\n0.000\n0.034\n0.011\n-0.032\n-0.002\n\n\nexhaustion_3\n-0.019\n-0.030\n0.047\n0.027\n-0.137\n-0.109\n-0.054\n0.032\n-0.014\n-0.130\n-0.031\n0.034\n0.000\n0.052\n0.073\n0.058\n\n\nexhaustion_4\n-0.022\n0.007\n0.060\n0.064\n0.008\n0.006\n-0.006\n0.040\n-0.036\n-0.072\n-0.053\n0.011\n0.052\n0.000\n0.011\n0.027\n\n\nscore_div100\n0.025\n-0.053\n-0.018\n-0.009\n-0.025\n0.013\n0.046\n0.068\n0.109\n-0.009\n0.098\n-0.032\n0.073\n0.011\n0.000\n-0.003\n\n\nstudy_year\n0.041\n-0.004\n-0.046\n0.009\n-0.031\n0.059\n0.043\n0.083\n0.128\n0.090\n0.123\n-0.002\n0.058\n0.027\n-0.003\n0.000\n\n\n\n\n\n\nThe following code chunk won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\n\n# full SEM fitted to down-sampled data, residual interitem correlations  \nall_res_corr &lt;- list()\nfor (i in 1:n_iterations){\n  res_corr &lt;- downsampled_data_residual_correlations[[i]]\n  all_res_corr &lt;- append(all_res_corr, res_corr[lower.tri(res_corr)]) \n}\n\nrange(unlist(all_res_corr)) \n\n[1] -0.2256855  0.3143270"
  },
  {
    "objectID": "R-code.html#table-s6-standardized-interitem-residual-covariances-fitted-full-model",
    "href": "R-code.html#table-s6-standardized-interitem-residual-covariances-fitted-full-model",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S6: Standardized interitem residual covariances, fitted full model",
    "text": "Table S6: Standardized interitem residual covariances, fitted full model\n\nCode# Table S6A unweighted complete data\nres_z = lavResiduals(fit_fullSEM, type = 'raw')$cov.z\nrange(res_z)\n\n[1] -2.918249  4.855455\n\nCodekbl(\n  round(res_z,2),\n  caption = \"Table S6A. Standardized residual covariances, full SEM\",\n)\n\n\n\nTable S6A. Standardized residual covariances, full SEM\n\n\ndeep_1\ndeep_2\ndeep_3\ndeep_4\nunreflective_1\nunreflective_2\nunreflective_3\ncynicism_1\ncynicism_2\ncynicism_3\nexhaustion_1\nexhaustion_2\nexhaustion_3\nexhaustion_4\nscore_div100\nstudy_year\n\n\n\ndeep_1\n0.00\n2.93\n-0.17\n-0.77\n0.04\n-0.65\n0.79\n-0.15\n-1.00\n0.16\n-1.71\n-0.51\n0.84\n-0.28\n0.96\n1.48\n\n\ndeep_2\n2.93\n0.00\n-2.44\n0.52\n0.45\n0.78\n-1.24\n-0.49\n-0.11\n-0.23\n-0.79\n0.81\n0.53\n0.31\n-1.25\n-0.57\n\n\ndeep_3\n-0.17\n-2.44\n0.00\n1.14\n-0.88\n-0.25\n0.68\n1.17\n0.41\n-0.23\n-0.61\n-0.99\n2.12\n0.33\n1.45\n1.06\n\n\ndeep_4\n-0.77\n0.52\n1.14\n0.00\n-0.31\n-0.91\n0.85\n0.22\n-0.78\n0.33\n-0.24\n-1.35\n1.87\n0.20\n1.18\n1.64\n\n\nunreflective_1\n0.04\n0.45\n-0.88\n-0.31\n0.00\n1.37\n-0.31\n0.66\n-2.92\n-1.57\n2.13\n-0.35\n-1.96\n0.17\n-0.74\n-1.17\n\n\nunreflective_2\n-0.65\n0.78\n-0.25\n-0.91\n1.37\n0.00\n-1.07\n0.41\n0.12\n1.87\n0.05\n-2.23\n-2.23\n0.29\n-0.04\n0.55\n\n\nunreflective_3\n0.79\n-1.24\n0.68\n0.85\n-0.31\n-1.07\n0.00\n1.50\n1.28\n-0.21\n2.44\n0.89\n-1.96\n-0.33\n-0.40\n-0.54\n\n\ncynicism_1\n-0.15\n-0.49\n1.17\n0.22\n0.66\n0.41\n1.50\n0.00\n-2.26\n-1.24\n4.86\n2.01\n0.35\n1.14\n0.41\n0.26\n\n\ncynicism_2\n-1.00\n-0.11\n0.41\n-0.78\n-2.92\n0.12\n1.28\n-2.26\n0.00\n3.19\n0.42\n-0.51\n-0.23\n-0.77\n1.83\n1.28\n\n\ncynicism_3\n0.16\n-0.23\n-0.23\n0.33\n-1.57\n1.87\n-0.21\n-1.24\n3.19\n0.00\n-0.68\n-0.76\n-2.70\n-1.72\n-1.28\n0.08\n\n\nexhaustion_1\n-1.71\n-0.79\n-0.61\n-0.24\n2.13\n0.05\n2.44\n4.86\n0.42\n-0.68\n0.00\n-0.53\n-0.74\n-2.14\n1.70\n1.87\n\n\nexhaustion_2\n-0.51\n0.81\n-0.99\n-1.35\n-0.35\n-2.23\n0.89\n2.01\n-0.51\n-0.76\n-0.53\n0.00\n0.73\n1.19\n-1.41\n-0.92\n\n\nexhaustion_3\n0.84\n0.53\n2.12\n1.87\n-1.96\n-2.23\n-1.96\n0.35\n-0.23\n-2.70\n-0.74\n0.73\n0.00\n1.54\n1.96\n1.19\n\n\nexhaustion_4\n-0.28\n0.31\n0.33\n0.20\n0.17\n0.29\n-0.33\n1.14\n-0.77\n-1.72\n-2.14\n1.19\n1.54\n0.00\n-0.14\n0.07\n\n\nscore_div100\n0.96\n-1.25\n1.45\n1.18\n-0.74\n-0.04\n-0.40\n0.41\n1.83\n-1.28\n1.70\n-1.41\n1.96\n-0.14\n1.38\n1.38\n\n\nstudy_year\n1.48\n-0.57\n1.06\n1.64\n-1.17\n0.55\n-0.54\n0.26\n1.28\n0.08\n1.87\n-0.92\n1.19\n0.07\n1.38\n0.00\n\n\n\n\n\n\nThe following code chunks won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\n# Table S6B weighted data\nres_z = lavResiduals(fit_weighted_fullSEM, type = 'raw')$cov.z\nrange(res_z)\n\n[1] -3.031664  5.414844\n\nCodekbl(\n  round(res_z,2),\n  caption = \"Table S6B. Standardized residual covariances, full SEM, weighted data\",\n)\n\n\n\nTable S6B. Standardized residual covariances, full SEM, weighted data\n\n\ndeep_1\ndeep_2\ndeep_3\ndeep_4\nunreflective_1\nunreflective_2\nunreflective_3\ncynicism_1\ncynicism_2\ncynicism_3\nexhaustion_1\nexhaustion_2\nexhaustion_3\nexhaustion_4\nscore_div100\nstudy_year\n\n\n\ndeep_1\n0.00\n3.02\n-0.24\n-0.52\n-1.11\n-0.42\n1.09\n0.23\n-0.42\n0.39\n-1.34\n-1.41\n-0.30\n-0.35\n0.40\n0.66\n\n\ndeep_2\n3.02\n0.00\n-1.90\n0.53\n-0.17\n1.38\n-0.58\n-0.36\n0.37\n-0.39\n-1.10\n-0.49\n-0.52\n0.13\n-0.84\n-0.06\n\n\ndeep_3\n-0.24\n-1.90\n0.00\n0.75\n-2.18\n-1.47\n2.04\n0.46\n0.30\n-0.32\n-0.45\n-1.44\n0.80\n1.53\n-0.40\n-0.68\n\n\ndeep_4\n-0.52\n0.53\n0.75\n0.00\n-1.28\n-0.77\n2.40\n0.19\n-0.68\n0.33\n-0.16\n-1.32\n0.45\n1.40\n-0.18\n0.14\n\n\nunreflective_1\n-1.11\n-0.17\n-2.18\n-1.28\n0.00\n0.85\n-0.51\n0.82\n-2.90\n-2.10\n2.00\n-0.24\n-2.96\n0.19\n-0.49\n-0.49\n\n\nunreflective_2\n-0.42\n1.38\n-1.47\n-0.77\n0.85\n0.00\n-0.35\n0.89\n0.70\n1.17\n-0.41\n-3.03\n-2.18\n0.13\n0.25\n0.98\n\n\nunreflective_3\n1.09\n-0.58\n2.04\n2.40\n-0.51\n-0.35\n0.00\n2.16\n1.28\n-0.42\n3.12\n0.82\n-1.12\n-0.17\n0.85\n0.64\n\n\ncynicism_1\n0.23\n-0.36\n0.46\n0.19\n0.82\n0.89\n2.16\n0.00\n-2.66\n-0.73\n5.41\n1.66\n0.62\n0.84\n1.30\n1.30\n\n\ncynicism_2\n-0.42\n0.37\n0.30\n-0.68\n-2.90\n0.70\n1.28\n-2.66\n0.00\n3.38\n0.92\n-0.14\n-0.32\n-1.11\n2.37\n1.99\n\n\ncynicism_3\n0.39\n-0.39\n-0.32\n0.33\n-2.10\n1.17\n-0.42\n-0.73\n3.38\n0.00\n-0.82\n-0.43\n-2.35\n-1.53\n-0.16\n1.35\n\n\nexhaustion_1\n-1.34\n-1.10\n-0.45\n-0.16\n2.00\n-0.41\n3.12\n5.41\n0.92\n-0.82\n0.00\n-0.03\n-1.01\n-2.57\n1.63\n1.85\n\n\nexhaustion_2\n-1.41\n-0.49\n-1.44\n-1.32\n-0.24\n-3.03\n0.82\n1.66\n-0.14\n-0.43\n-0.03\n0.00\n1.11\n0.62\n-0.60\n-0.03\n\n\nexhaustion_3\n-0.30\n-0.52\n0.80\n0.45\n-2.96\n-2.18\n-1.12\n0.62\n-0.32\n-2.35\n-1.01\n1.11\n0.00\n1.89\n1.25\n0.91\n\n\nexhaustion_4\n-0.35\n0.13\n1.53\n1.40\n0.19\n0.13\n-0.17\n0.84\n-1.11\n-1.53\n-2.57\n0.62\n1.89\n0.00\n0.21\n0.41\n\n\nscore_div100\n0.40\n-0.84\n-0.40\n-0.18\n-0.49\n0.25\n0.85\n1.30\n2.37\n-0.16\n1.63\n-0.60\n1.25\n0.21\n-0.41\n-0.41\n\n\nstudy_year\n0.66\n-0.06\n-0.68\n0.14\n-0.49\n0.98\n0.64\n1.30\n1.99\n1.35\n1.85\n-0.03\n0.91\n0.41\n-0.41\n0.00\n\n\n\n\n\n\nThe following code chunk won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\n# full SEM fitted to down-sampled data, standardized residual covariances  \nall_resz &lt;- list()\nfor (i in 1:n_iterations){\n  res_z &lt;- downsampled_data_standardized_residual_covariances[[i]]\n  all_resz &lt;- append(all_resz, res_z[lower.tri(res_z)]) \n}\nrange(unlist(all_resz))\n\n[1] -4.361720  5.287087"
  },
  {
    "objectID": "R-code.html#table-s7.-full-model-standardized-parameters",
    "href": "R-code.html#table-s7.-full-model-standardized-parameters",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S7. Full model, standardized parameters",
    "text": "Table S7. Full model, standardized parameters\n\nTable S7A: unweighted complete data\nTable S7B: weighted data (This code won’t run on the anonymous data.)\n\n\nCode# Table S7A\nSTable7A &lt;- standardizedSolution(fit_fullSEM, output = 'data.frame')\nSTable7A[\"h2\"] &lt;-  NA\nSTable7A[STable7A$op == \"=~\", \"h2\"] &lt;- STable7A[STable7A$op == \"=~\", \"est.std\"]^2\ntableS7A &lt;- cbind(STable7A[1:3], round(STable7A[4:ncol(STable7A)], 2))\n\nkbl(\n  tableS7A,\n  caption = \"Table S7A. Parameter estimates from full SEM fitted on unweighted data\"\n) \n\n\n\nTable S7A. Parameter estimates from full SEM fitted on unweighted data\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\nh2\n\n\n\nf_deep\n=~\ndeep_1\n0.50\n0.06\n8.37\n0.00\n0.38\n0.61\n0.25\n\n\nf_deep\n=~\ndeep_2\n0.37\n0.07\n5.50\n0.00\n0.24\n0.50\n0.14\n\n\nf_deep\n=~\ndeep_3\n0.84\n0.04\n18.60\n0.00\n0.75\n0.92\n0.70\n\n\nf_deep\n=~\ndeep_4\n0.81\n0.05\n17.43\n0.00\n0.72\n0.90\n0.66\n\n\nf_unreflective\n=~\nunreflective_1\n0.62\n0.06\n11.19\n0.00\n0.51\n0.73\n0.39\n\n\nf_unreflective\n=~\nunreflective_2\n0.53\n0.07\n8.18\n0.00\n0.41\n0.66\n0.28\n\n\nf_unreflective\n=~\nunreflective_3\n0.68\n0.06\n11.94\n0.00\n0.57\n0.79\n0.46\n\n\nf_cynicism\n=~\ncynicism_1\n0.70\n0.05\n15.54\n0.00\n0.61\n0.79\n0.49\n\n\nf_cynicism\n=~\ncynicism_2\n0.86\n0.04\n23.53\n0.00\n0.78\n0.93\n0.73\n\n\nf_cynicism\n=~\ncynicism_3\n0.74\n0.04\n18.19\n0.00\n0.66\n0.82\n0.54\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.64\n0.05\n13.32\n0.00\n0.55\n0.74\n0.41\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.67\n0.05\n12.62\n0.00\n0.57\n0.78\n0.46\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.53\n0.06\n8.76\n0.00\n0.41\n0.64\n0.28\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.69\n0.05\n14.59\n0.00\n0.60\n0.78\n0.48\n\n\nscore_div100\n~\nf_deep\n0.16\n0.06\n2.46\n0.01\n0.03\n0.28\nNA\n\n\nscore_div100\n~\nstudy_year\n0.68\n0.03\n23.52\n0.00\n0.62\n0.73\nNA\n\n\nscore_div100\n~\nf_unreflective\n-0.25\n0.11\n-2.24\n0.03\n-0.47\n-0.03\nNA\n\n\nscore_div100\n~\nf_cynicism\n0.00\n0.07\n0.01\n1.00\n-0.14\n0.14\nNA\n\n\nscore_div100\n~\nf_exhaustion\n0.10\n0.10\n1.02\n0.31\n-0.09\n0.30\nNA\n\n\nf_cynicism\n~~\nf_exhaustion\n0.54\n0.06\n8.43\n0.00\n0.41\n0.66\nNA\n\n\nf_unreflective\n~~\nf_cynicism\n0.56\n0.08\n6.76\n0.00\n0.39\n0.72\nNA\n\n\nf_unreflective\n~~\nf_exhaustion\n0.63\n0.07\n8.54\n0.00\n0.49\n0.78\nNA\n\n\nf_deep\n~~\nf_unreflective\n-0.29\n0.08\n-3.53\n0.00\n-0.46\n-0.13\nNA\n\n\ndeep_1\n~~\ndeep_1\n0.75\n0.06\n12.77\n0.00\n0.64\n0.87\nNA\n\n\ndeep_2\n~~\ndeep_2\n0.86\n0.05\n17.46\n0.00\n0.77\n0.96\nNA\n\n\ndeep_3\n~~\ndeep_3\n0.30\n0.08\n4.01\n0.00\n0.15\n0.45\nNA\n\n\ndeep_4\n~~\ndeep_4\n0.34\n0.08\n4.55\n0.00\n0.20\n0.49\nNA\n\n\nunreflective_1\n~~\nunreflective_1\n0.61\n0.07\n8.80\n0.00\n0.48\n0.75\nNA\n\n\nunreflective_2\n~~\nunreflective_2\n0.72\n0.07\n10.27\n0.00\n0.58\n0.85\nNA\n\n\nunreflective_3\n~~\nunreflective_3\n0.54\n0.08\n7.03\n0.00\n0.39\n0.69\nNA\n\n\ncynicism_1\n~~\ncynicism_1\n0.51\n0.06\n8.09\n0.00\n0.39\n0.63\nNA\n\n\ncynicism_2\n~~\ncynicism_2\n0.27\n0.06\n4.30\n0.00\n0.15\n0.39\nNA\n\n\ncynicism_3\n~~\ncynicism_3\n0.46\n0.06\n7.68\n0.00\n0.34\n0.57\nNA\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.59\n0.06\n9.44\n0.00\n0.46\n0.71\nNA\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.54\n0.07\n7.54\n0.00\n0.40\n0.69\nNA\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.72\n0.06\n11.51\n0.00\n0.60\n0.85\nNA\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.52\n0.07\n7.96\n0.00\n0.39\n0.65\nNA\n\n\nscore_div100\n~~\nscore_div100\n0.45\n0.04\n11.32\n0.00\n0.37\n0.53\nNA\n\n\nf_deep\n~~\nf_deep\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_deep\n~~\nf_cynicism\n-0.19\n0.09\n-2.07\n0.04\n-0.37\n-0.01\nNA\n\n\nf_deep\n~~\nf_exhaustion\n0.08\n0.08\n1.10\n0.27\n-0.07\n0.23\nNA\n\n\nstudy_year\n~~\nstudy_year\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\n\n\n\n\nThe following code chunk won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\nSTable7B &lt;- standardizedSolution(fit_weighted_fullSEM, output = 'data.frame')\n\nSTable7B[\"h2\"] &lt;-  NA\nSTable7B [ STable7B$op == \"=~\", \"h2\"] &lt;-  (STable7B [ STable7B$op == \"=~\", \"est.std\"])^2\ntableS7B &lt;- cbind(\n  STable7B[1:3],\n  round(STable7B[4:ncol(STable7B)], 2)\n)\n\nkbl(\n  tableS7B,\n  caption = \"Table S7B. Parameter estimates from full SEM fitted on weighted data\"\n)\n\n\n\nTable S7B. Parameter estimates from full SEM fitted on weighted data\n\nlhs\nop\nrhs\nest.std\nse\nz\npvalue\nci.lower\nci.upper\nh2\n\n\n\nf_deep\n=~\ndeep_1\n0.48\n0.06\n7.46\n0.00\n0.35\n0.60\n0.23\n\n\nf_deep\n=~\ndeep_2\n0.34\n0.07\n4.90\n0.00\n0.20\n0.47\n0.11\n\n\nf_deep\n=~\ndeep_3\n0.90\n0.05\n17.19\n0.00\n0.79\n1.00\n0.80\n\n\nf_deep\n=~\ndeep_4\n0.79\n0.05\n15.32\n0.00\n0.68\n0.89\n0.62\n\n\nf_unreflective\n=~\nunreflective_1\n0.62\n0.06\n10.92\n0.00\n0.51\n0.73\n0.38\n\n\nf_unreflective\n=~\nunreflective_2\n0.52\n0.07\n7.77\n0.00\n0.39\n0.65\n0.27\n\n\nf_unreflective\n=~\nunreflective_3\n0.68\n0.06\n11.45\n0.00\n0.56\n0.79\n0.46\n\n\nf_cynicism\n=~\ncynicism_1\n0.70\n0.04\n15.88\n0.00\n0.62\n0.79\n0.49\n\n\nf_cynicism\n=~\ncynicism_2\n0.88\n0.04\n24.15\n0.00\n0.81\n0.96\n0.78\n\n\nf_cynicism\n=~\ncynicism_3\n0.76\n0.04\n18.65\n0.00\n0.68\n0.84\n0.58\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.65\n0.05\n13.98\n0.00\n0.56\n0.74\n0.42\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.68\n0.05\n13.48\n0.00\n0.58\n0.77\n0.46\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.56\n0.06\n10.13\n0.00\n0.45\n0.67\n0.31\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.74\n0.04\n16.55\n0.00\n0.65\n0.83\n0.55\n\n\nscore_div100\n~\nf_deep\n0.11\n0.06\n1.70\n0.09\n-0.02\n0.24\nNA\n\n\nscore_div100\n~\nstudy_year\n0.66\n0.03\n21.26\n0.00\n0.59\n0.72\nNA\n\n\nscore_div100\n~\nf_unreflective\n-0.27\n0.11\n-2.40\n0.02\n-0.49\n-0.05\nNA\n\n\nscore_div100\n~\nf_cynicism\n0.03\n0.08\n0.41\n0.68\n-0.12\n0.18\nNA\n\n\nscore_div100\n~\nf_exhaustion\n0.11\n0.10\n1.08\n0.28\n-0.09\n0.31\nNA\n\n\nf_cynicism\n~~\nf_exhaustion\n0.52\n0.06\n8.60\n0.00\n0.40\n0.64\nNA\n\n\nf_unreflective\n~~\nf_cynicism\n0.52\n0.08\n6.35\n0.00\n0.36\n0.68\nNA\n\n\nf_unreflective\n~~\nf_exhaustion\n0.64\n0.07\n9.09\n0.00\n0.50\n0.78\nNA\n\n\nf_deep\n~~\nf_unreflective\n-0.18\n0.09\n-2.12\n0.03\n-0.35\n-0.01\nNA\n\n\ndeep_1\n~~\ndeep_1\n0.77\n0.06\n12.69\n0.00\n0.65\n0.89\nNA\n\n\ndeep_2\n~~\ndeep_2\n0.89\n0.05\n18.96\n0.00\n0.79\n0.98\nNA\n\n\ndeep_3\n~~\ndeep_3\n0.20\n0.09\n2.12\n0.03\n0.01\n0.38\nNA\n\n\ndeep_4\n~~\ndeep_4\n0.38\n0.08\n4.77\n0.00\n0.23\n0.54\nNA\n\n\nunreflective_1\n~~\nunreflective_1\n0.62\n0.07\n8.75\n0.00\n0.48\n0.75\nNA\n\n\nunreflective_2\n~~\nunreflective_2\n0.73\n0.07\n10.64\n0.00\n0.60\n0.87\nNA\n\n\nunreflective_3\n~~\nunreflective_3\n0.54\n0.08\n6.81\n0.00\n0.39\n0.70\nNA\n\n\ncynicism_1\n~~\ncynicism_1\n0.51\n0.06\n8.15\n0.00\n0.38\n0.63\nNA\n\n\ncynicism_2\n~~\ncynicism_2\n0.22\n0.06\n3.37\n0.00\n0.09\n0.35\nNA\n\n\ncynicism_3\n~~\ncynicism_3\n0.42\n0.06\n6.80\n0.00\n0.30\n0.54\nNA\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.58\n0.06\n9.65\n0.00\n0.46\n0.70\nNA\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.54\n0.07\n8.01\n0.00\n0.41\n0.68\nNA\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.69\n0.06\n11.18\n0.00\n0.57\n0.81\nNA\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.45\n0.07\n6.74\n0.00\n0.32\n0.58\nNA\n\n\nscore_div100\n~~\nscore_div100\n0.50\n0.04\n12.12\n0.00\n0.42\n0.58\nNA\n\n\nf_deep\n~~\nf_deep\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA\n\n\nf_deep\n~~\nf_cynicism\n-0.13\n0.09\n-1.45\n0.15\n-0.30\n0.05\nNA\n\n\nf_deep\n~~\nf_exhaustion\n0.14\n0.07\n1.94\n0.05\n0.00\n0.28\nNA\n\n\nstudy_year\n~~\nstudy_year\n1.00\n0.00\nNA\nNA\n1.00\n1.00\nNA"
  },
  {
    "objectID": "R-code.html#table-s8-parameter-estimates-from-measurement-models-fitted-to-downsampled-data",
    "href": "R-code.html#table-s8-parameter-estimates-from-measurement-models-fitted-to-downsampled-data",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S8: Parameter estimates from measurement models fitted to downsampled data",
    "text": "Table S8: Parameter estimates from measurement models fitted to downsampled data\nThe following code chunk won’t run on anonymous data.\n\nCoden_iterations &lt;- length(downsampled_data_parameter_list)\ntableS8 &lt;- downsampled_data_parameter_list[[1]][1:6]\nfor (i in 2:n_iterations){\n  tableS8 &lt;- cbind(tableS8, downsampled_data_parameter_list[[i]][4:6])\n}\n\nmy_quantile &lt;- function(x, probs){\n  return(\n    quantile(\n      x = x, \n      probs = probs , \n      na.rm = TRUE\n    )\n  )\n}\n\ntableS8 &lt;- cbind(\n  tableS8[1:3],\n  mean.est.std = apply(tableS8[(grepl(\"est\", colnames(tableS8)))], 1, mean), \n  t(apply(tableS8[(grepl(\"est\", colnames(tableS8)))], 1, my_quantile, c(0.025, 0.975))),\n  mean.se = apply(tableS8[(grepl(\"se\", colnames(tableS8)))], 1, mean), \n  t(apply(tableS8[(grepl(\"se\", colnames(tableS8)))], 1, my_quantile, c(0.025, 0.975))),\n  mean.z = apply(tableS8[(grepl(\"z\", colnames(tableS8)))], 1, mean), \n  t(apply(tableS8[(grepl(\"z\", colnames(tableS8)))], 1, my_quantile, c(0.025, 0.975)))\n)\n\n\ncolnames(tableS8)[c(4,7,10)] &lt;- c(\"mean.est.std\", \"mean.se\", \"mean.z\")\ncolnames(tableS8)[8:9] &lt;- paste(\" \", colnames(tableS8)[8:9], sep = '') \ncolnames(tableS8)[11:12] &lt;- paste(\"  \", colnames(tableS8)[11:12], sep = '') \nkbl(\n  cbind(\n    tableS8[1:3],\n    round(tableS8[4:ncol(tableS8)], 2)\n  ),\n  caption = \"Table S8. Parameter estimates from measurement model fitted on downsampled data\",\n)\n\n\n\nTable S8. Parameter estimates from measurement model fitted on downsampled data\n\nlhs\nop\nrhs\nmean.est.std\n2.5%\n97.5%\nmean.se\n2.5%\n97.5%\nmean.z\n2.5%\n97.5%\n\n\n\nf_deep\n=~\ndeep_1\n0.49\n0.43\n0.55\n0.07\n0.06\n0.07\n7.35\n6.00\n8.57\n\n\nf_deep\n=~\ndeep_2\n0.36\n0.30\n0.41\n0.08\n0.08\n0.09\n4.43\n3.55\n5.28\n\n\nf_deep\n=~\ndeep_3\n0.85\n0.80\n0.90\n0.05\n0.04\n0.07\n16.84\n11.71\n22.05\n\n\nf_deep\n=~\ndeep_4\n0.79\n0.75\n0.83\n0.06\n0.05\n0.07\n13.35\n11.19\n15.63\n\n\nf_unreflective\n=~\nunreflective_1\n0.64\n0.59\n0.68\n0.07\n0.06\n0.07\n9.31\n7.95\n10.77\n\n\nf_unreflective\n=~\nunreflective_2\n0.52\n0.47\n0.58\n0.08\n0.07\n0.09\n6.54\n5.49\n7.70\n\n\nf_unreflective\n=~\nunreflective_3\n0.67\n0.61\n0.72\n0.07\n0.07\n0.08\n9.32\n7.93\n10.74\n\n\nf_cynicism\n=~\ncynicism_1\n0.71\n0.67\n0.75\n0.05\n0.05\n0.06\n13.71\n11.74\n15.72\n\n\nf_cynicism\n=~\ncynicism_2\n0.88\n0.83\n0.92\n0.04\n0.03\n0.05\n23.10\n17.67\n28.79\n\n\nf_cynicism\n=~\ncynicism_3\n0.75\n0.71\n0.78\n0.05\n0.04\n0.05\n16.05\n13.83\n18.44\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.63\n0.58\n0.67\n0.06\n0.05\n0.06\n11.11\n9.41\n12.94\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.66\n0.62\n0.70\n0.06\n0.06\n0.07\n10.93\n9.20\n12.42\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.58\n0.53\n0.62\n0.07\n0.07\n0.08\n8.18\n7.01\n9.16\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.74\n0.69\n0.79\n0.05\n0.04\n0.06\n15.59\n12.66\n18.64\n\n\ndeep_1\n~~\ndeep_1\n0.76\n0.70\n0.82\n0.07\n0.06\n0.07\n11.64\n9.69\n13.77\n\n\ndeep_2\n~~\ndeep_2\n0.87\n0.83\n0.91\n0.06\n0.05\n0.07\n15.24\n12.57\n18.56\n\n\ndeep_3\n~~\ndeep_3\n0.27\n0.20\n0.35\n0.09\n0.07\n0.11\n3.05\n2.28\n3.74\n\n\ndeep_4\n~~\ndeep_4\n0.38\n0.31\n0.44\n0.09\n0.08\n0.11\n4.03\n3.17\n4.80\n\n\nunreflective_1\n~~\nunreflective_1\n0.59\n0.53\n0.65\n0.09\n0.08\n0.09\n6.75\n5.96\n7.62\n\n\nunreflective_2\n~~\nunreflective_2\n0.73\n0.67\n0.78\n0.08\n0.08\n0.09\n8.74\n7.60\n10.02\n\n\nunreflective_3\n~~\nunreflective_3\n0.55\n0.48\n0.62\n0.10\n0.09\n0.10\n5.79\n4.79\n6.81\n\n\ncynicism_1\n~~\ncynicism_1\n0.49\n0.43\n0.56\n0.07\n0.07\n0.08\n6.66\n5.80\n7.58\n\n\ncynicism_2\n~~\ncynicism_2\n0.22\n0.15\n0.31\n0.07\n0.06\n0.08\n3.25\n2.33\n4.08\n\n\ncynicism_3\n~~\ncynicism_3\n0.44\n0.39\n0.50\n0.07\n0.07\n0.07\n6.37\n5.69\n7.12\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.60\n0.55\n0.66\n0.07\n0.07\n0.07\n8.50\n7.77\n9.26\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.56\n0.51\n0.62\n0.08\n0.08\n0.09\n6.90\n6.23\n7.61\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.67\n0.62\n0.72\n0.08\n0.08\n0.09\n8.13\n7.27\n9.15\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.45\n0.37\n0.52\n0.07\n0.07\n0.08\n6.28\n5.37\n7.21\n\n\nf_deep\n~~\nf_deep\n1.00\n1.00\n1.00\n0.00\n0.00\n0.00\nNA\nNA\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n1.00\n1.00\n0.00\n0.00\n0.00\nNA\nNA\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n1.00\n1.00\n0.00\n0.00\n0.00\nNA\nNA\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n1.00\n1.00\n0.00\n0.00\n0.00\nNA\nNA\nNA\n\n\nf_deep\n~~\nf_unreflective\n-0.28\n-0.36\n-0.20\n0.10\n0.10\n0.11\n-2.73\n-3.62\n-1.89\n\n\nf_deep\n~~\nf_cynicism\n-0.19\n-0.27\n-0.11\n0.11\n0.10\n0.11\n-1.80\n-2.54\n-1.03\n\n\nf_deep\n~~\nf_exhaustion\n0.10\n0.05\n0.16\n0.09\n0.09\n0.10\n1.11\n0.49\n1.74\n\n\nf_unreflective\n~~\nf_cynicism\n0.51\n0.46\n0.57\n0.10\n0.10\n0.11\n5.02\n4.35\n5.70\n\n\nf_unreflective\n~~\nf_exhaustion\n0.59\n0.53\n0.64\n0.09\n0.09\n0.10\n6.34\n5.37\n7.34\n\n\nf_cynicism\n~~\nf_exhaustion\n0.50\n0.45\n0.55\n0.07\n0.07\n0.08\n6.81\n5.69\n7.87"
  },
  {
    "objectID": "R-code.html#table-s9-parameter-estimates-from-full-se-models-fitted-to-downsampled-data",
    "href": "R-code.html#table-s9-parameter-estimates-from-full-se-models-fitted-to-downsampled-data",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S9: Parameter estimates from full SE models fitted to downsampled data",
    "text": "Table S9: Parameter estimates from full SE models fitted to downsampled data\nThe following code chunk won’t run on anonymous data.\n\nCode# This code won't run on the anonymous data.\n\nn_iterations &lt;- length(downsampled_data_parameter_list_fullSEM)\ntableS9 &lt;- downsampled_data_parameter_list_fullSEM[[1]][1:6]\nfor (i in 2:n_iterations){\n  tableS9 &lt;- cbind(tableS9, downsampled_data_parameter_list_fullSEM[[i]][4:6])\n}\n\nmy_quantile &lt;- function(x, probs){\n  return(quantile(x = x, probs = probs , na.rm = TRUE))\n}\n\ntableS9 &lt;- cbind(\n  tableS9[1:3],\n  mean.est.std = apply(tableS9[(grepl(\"est\", colnames(tableS9)))], 1, mean), \n  t(apply(tableS9[(grepl(\"est\", colnames(tableS9)))], 1, my_quantile, c(0.025, 0.975))),\n  mean.se = apply(tableS9[(grepl(\"se\", colnames(tableS9)))], 1, mean), \n  t(apply(tableS9[(grepl(\"se\", colnames(tableS8)))], 1, my_quantile, c(0.025, 0.975))),\n  mean.z = apply(tableS9[(grepl(\"z\", colnames(tableS9)))], 1, mean), \n  t(apply(tableS9[(grepl(\"z\", colnames(tableS9)))], 1, my_quantile, c(0.025, 0.975)))\n)\n\ncolnames(tableS9) &lt;- colnames(tableS8)\nkbl(\n  cbind(\n    tableS9[1:3],\n    round(tableS9[4:ncol(tableS9)], 2)\n  ),\n  caption = \"Table S9. Parameter estimates from full SEM fitted on downsampled data\"\n) \n\n\n\nTable S9. Parameter estimates from full SEM fitted on downsampled data\n\nlhs\nop\nrhs\nmean.est.std\n2.5%\n97.5%\nmean.se\n2.5%\n97.5%\nmean.z\n2.5%\n97.5%\n\n\n\nf_deep\n=~\ndeep_1\n0.49\n0.42\n0.55\n0.07\n0.42\n0.55\n7.27\n5.92\n8.51\n\n\nf_deep\n=~\ndeep_2\n0.35\n0.29\n0.41\n0.08\n0.29\n0.40\n4.35\n3.46\n5.20\n\n\nf_deep\n=~\ndeep_3\n0.87\n0.82\n0.91\n0.05\n0.82\n0.91\n17.95\n12.53\n23.75\n\n\nf_deep\n=~\ndeep_4\n0.78\n0.74\n0.82\n0.06\n0.74\n0.81\n13.21\n11.21\n15.38\n\n\nf_unreflective\n=~\nunreflective_1\n0.64\n0.58\n0.68\n0.07\n0.58\n0.68\n9.48\n7.99\n11.16\n\n\nf_unreflective\n=~\nunreflective_2\n0.53\n0.47\n0.58\n0.08\n0.47\n0.59\n6.72\n5.64\n7.93\n\n\nf_unreflective\n=~\nunreflective_3\n0.67\n0.61\n0.72\n0.07\n0.61\n0.72\n9.45\n8.01\n10.91\n\n\nf_cynicism\n=~\ncynicism_1\n0.71\n0.67\n0.75\n0.05\n0.67\n0.75\n13.72\n11.74\n15.73\n\n\nf_cynicism\n=~\ncynicism_2\n0.88\n0.83\n0.93\n0.04\n0.83\n0.92\n23.05\n17.64\n28.77\n\n\nf_cynicism\n=~\ncynicism_3\n0.75\n0.71\n0.78\n0.05\n0.71\n0.78\n16.07\n13.87\n18.51\n\n\nf_exhaustion\n=~\nexhaustion_1\n0.63\n0.58\n0.67\n0.06\n0.58\n0.67\n11.11\n9.38\n12.94\n\n\nf_exhaustion\n=~\nexhaustion_2\n0.66\n0.62\n0.70\n0.06\n0.62\n0.70\n10.92\n9.18\n12.44\n\n\nf_exhaustion\n=~\nexhaustion_3\n0.58\n0.53\n0.62\n0.07\n0.53\n0.62\n8.17\n7.02\n9.17\n\n\nf_exhaustion\n=~\nexhaustion_4\n0.74\n0.69\n0.79\n0.05\n0.70\n0.79\n15.59\n12.63\n18.63\n\n\nscore_div100\n~\nf_deep\n0.12\n0.04\n0.19\n0.07\n0.04\n0.19\n1.59\n0.57\n2.67\n\n\nscore_div100\n~\nstudy_year\n0.65\n0.62\n0.67\n0.04\n0.62\n0.67\n16.50\n14.94\n18.09\n\n\nscore_div100\n~\nf_unreflective\n-0.23\n-0.32\n-0.14\n0.13\n-0.32\n-0.14\n-1.81\n-2.50\n-1.09\n\n\nscore_div100\n~\nf_cynicism\n0.03\n-0.04\n0.09\n0.09\n-0.04\n0.09\n0.29\n-0.46\n1.04\n\n\nscore_div100\n~\nf_exhaustion\n0.06\n-0.01\n0.14\n0.11\n0.00\n0.14\n0.56\n-0.11\n1.20\n\n\nf_cynicism\n~~\nf_exhaustion\n0.50\n0.45\n0.55\n0.07\n0.45\n0.55\n6.81\n5.69\n7.86\n\n\nf_unreflective\n~~\nf_cynicism\n0.52\n0.46\n0.57\n0.10\n0.45\n0.57\n5.02\n4.36\n5.70\n\n\nf_unreflective\n~~\nf_exhaustion\n0.59\n0.53\n0.64\n0.09\n0.53\n0.63\n6.33\n5.37\n7.35\n\n\nf_deep\n~~\nf_unreflective\n-0.28\n-0.36\n-0.20\n0.10\n-0.35\n-0.21\n-2.75\n-3.64\n-1.95\n\n\ndeep_1\n~~\ndeep_1\n0.76\n0.70\n0.82\n0.07\n0.70\n0.82\n11.69\n9.69\n13.93\n\n\ndeep_2\n~~\ndeep_2\n0.88\n0.83\n0.92\n0.06\n0.84\n0.91\n15.66\n12.83\n19.33\n\n\ndeep_3\n~~\ndeep_3\n0.25\n0.17\n0.33\n0.09\n0.17\n0.33\n2.91\n2.06\n3.63\n\n\ndeep_4\n~~\ndeep_4\n0.39\n0.33\n0.45\n0.09\n0.34\n0.45\n4.26\n3.41\n5.08\n\n\nunreflective_1\n~~\nunreflective_1\n0.60\n0.53\n0.66\n0.09\n0.54\n0.66\n6.99\n6.15\n7.88\n\n\nunreflective_2\n~~\nunreflective_2\n0.72\n0.66\n0.78\n0.08\n0.65\n0.78\n8.70\n7.59\n9.99\n\n\nunreflective_3\n~~\nunreflective_3\n0.56\n0.48\n0.63\n0.09\n0.48\n0.62\n5.93\n4.97\n7.00\n\n\ncynicism_1\n~~\ncynicism_1\n0.49\n0.43\n0.56\n0.07\n0.44\n0.55\n6.66\n5.81\n7.58\n\n\ncynicism_2\n~~\ncynicism_2\n0.22\n0.14\n0.31\n0.07\n0.15\n0.31\n3.26\n2.30\n4.10\n\n\ncynicism_3\n~~\ncynicism_3\n0.44\n0.39\n0.50\n0.07\n0.39\n0.50\n6.35\n5.68\n7.11\n\n\nexhaustion_1\n~~\nexhaustion_1\n0.60\n0.55\n0.66\n0.07\n0.55\n0.66\n8.49\n7.75\n9.27\n\n\nexhaustion_2\n~~\nexhaustion_2\n0.56\n0.51\n0.62\n0.08\n0.51\n0.62\n6.90\n6.23\n7.61\n\n\nexhaustion_3\n~~\nexhaustion_3\n0.67\n0.62\n0.72\n0.08\n0.61\n0.72\n8.13\n7.27\n9.13\n\n\nexhaustion_4\n~~\nexhaustion_4\n0.45\n0.37\n0.52\n0.07\n0.37\n0.51\n6.27\n5.36\n7.21\n\n\nscore_div100\n~~\nscore_div100\n0.51\n0.48\n0.54\n0.05\n0.48\n0.54\n10.11\n8.90\n11.21\n\n\nf_deep\n~~\nf_deep\n1.00\n1.00\n1.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nf_unreflective\n~~\nf_unreflective\n1.00\n1.00\n1.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nf_cynicism\n~~\nf_cynicism\n1.00\n1.00\n1.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nf_exhaustion\n~~\nf_exhaustion\n1.00\n1.00\n1.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nf_deep\n~~\nf_cynicism\n-0.19\n-0.27\n-0.11\n0.10\n-0.27\n-0.11\n-1.80\n-2.53\n-1.02\n\n\nf_deep\n~~\nf_exhaustion\n0.10\n0.05\n0.16\n0.09\n0.04\n0.16\n1.12\n0.50\n1.75\n\n\nstudy_year\n~~\nstudy_year\n1.00\n1.00\n1.00\n0.00\n1.00\n1.00\nNA\nNA\nNA"
  },
  {
    "objectID": "R-code.html#table-s10-raw-score-medians-by-gender",
    "href": "R-code.html#table-s10-raw-score-medians-by-gender",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Table S10: Raw score medians by gender",
    "text": "Table S10: Raw score medians by gender\nThe following code chunks won’t run on anonymous data.\n\nCode# The following code chunk won't run on anonymous data.\ndata &lt;- raw_data[,c(2,5:11,13:19, 23, 26:28)]\nkbl(\n  head(data, 3)\n)\n\n\n\n\ngender\ndeep_1\ndeep_2\ndeep_3\ndeep_4\nunreflective_1\nunreflective_2\nunreflective_3\ncynicism_1\ncynicism_2\ncynicism_3\nexhaustion_1\nexhaustion_2\nexhaustion_3\nexhaustion_4\nraw_deep\nraw_unreflective\nraw_cynicism\nraw_exhaustion\n\n\n\n2\n2\n1\n3\n3\n1\n3\n2\n2\n1\n1\n3\n2\n2\n2\n9\n6\n4\n9\n\n\n1\n3\n3\n3\n2\n0\n1\n0\n0\n0\n0\n1\n3\n3\n3\n11\n1\n0\n10\n\n\n2\n2\n2\n3\n3\n2\n1\n1\n0\n1\n1\n1\n0\n3\n1\n10\n4\n2\n5\n\n\n\n\n\n\n\nCode# The following code chunk won't run on anonymous data.\nstable10 &lt;- cbind(\n  males = apply(subset(data, gender == 1), 2, median),\n  females = apply(subset(data, gender == 2), 2, median),\n  difference = apply(subset(data, gender == 1), 2, median) - \n    apply(subset(data, gender == 2), 2, median)\n)\n\nkbl(\n  data.frame(stable10[-1,]),\n  caption = \"Table S10. Gender differences in the median values of the items and scale sum scores\"\n) \n\n\n\nTable S10. Gender differences in the median values of the items and scale sum scores\n\n\nmales\nfemales\ndifference\n\n\n\ndeep_1\n2\n2\n0\n\n\ndeep_2\n2\n2\n0\n\n\ndeep_3\n3\n3\n0\n\n\ndeep_4\n3\n3\n0\n\n\nunreflective_1\n1\n1\n0\n\n\nunreflective_2\n1\n1\n0\n\n\nunreflective_3\n1\n1\n0\n\n\ncynicism_1\n1\n2\n-1\n\n\ncynicism_2\n1\n1\n0\n\n\ncynicism_3\n0\n1\n-1\n\n\nexhaustion_1\n2\n3\n-1\n\n\nexhaustion_2\n1\n1\n0\n\n\nexhaustion_3\n1\n2\n-1\n\n\nexhaustion_4\n1\n2\n-1\n\n\nraw_deep\n10\n10\n0\n\n\nraw_unreflective\n3\n4\n-1\n\n\nraw_cynicism\n3\n3\n0\n\n\nraw_exhaustion\n4\n8\n-4"
  },
  {
    "objectID": "R-code.html#figure-1-unreflective-approach-items---information-and-probability-as-a-function-of-theta",
    "href": "R-code.html#figure-1-unreflective-approach-items---information-and-probability-as-a-function-of-theta",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 1: Unreflective approach items - information and probability as a function of \\(\\theta\\)\n",
    "text": "Figure 1: Unreflective approach items - information and probability as a function of \\(\\theta\\)\n\n\nCode# Information\nfit_unreflective_IRTgraded &lt;- mirt(data=raw_data[scale_unreflective4],  \n                      itemtype = 'graded', \n                      verbose = FALSE,\n                      model = 1)\nsummary(fit_unreflective_IRTgraded)\n\n                  F1    h2\nunreflective_1 0.807 0.652\nunreflective_2 0.571 0.326\nunreflective_3 0.649 0.421\nunreflective_4 0.328 0.107\n\nSS loadings:  1.507 \nProportion Var:  0.377 \n\nFactor correlations: \n\n   F1\nF1  1\n\nCodeplot(fit_unreflective_IRTgraded, type = 'infotrace') # Figure 1 upper row\n\n\n\nFigure 1, upper row. Information of scale items as a function of theta\n\n\n\n\nCode# Probabilities\n# Figure 1 lower row, unreflective_1\nitemplot(fit_unreflective_IRTgraded, 1, type = 'trace', main = 'unreflective_1') \n\n\n\nFigure 1, lower row. Probability of a scale item as a function of theta.\n\n\nCode# Figure 1 lower row, unreflective_2\nitemplot(fit_unreflective_IRTgraded, 2, type = 'trace', main = 'unreflective_2') \n\n\n\nFigure 1, lower row. Probability of a scale item as a function of theta.\n\n\nCode# Figure 1 lower row, unreflective_3\nitemplot(fit_unreflective_IRTgraded, 3, type = 'trace', main = 'unreflective_3') \n\n\n\nFigure 1, lower row. Probability of a scale item as a function of theta.\n\n\nCode# Figure 1 lower row, unreflective_4\nitemplot(fit_unreflective_IRTgraded, 4, type = 'trace', main = 'unreflective_4') \n\n\n\nFigure 1, lower row. Probability of a scale item as a function of theta."
  },
  {
    "objectID": "R-code.html#figure-2-vetrepos-test-score-distribution",
    "href": "R-code.html#figure-2-vetrepos-test-score-distribution",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 2: VetRepos test score distribution",
    "text": "Figure 2: VetRepos test score distribution\n\nCodehist(raw_data['vetrepos_score']) # Figure 2A\n\n\n\nFigure 2A. Distribution of the VetRepos score\n\n\n\n\nCode# This code chunk won't run on anonymous data.\nboxplot(vetrepos_score ~ study_year, data = raw_data) # Figure 2B\n\n\n\nFigure 2B. VetRepos score by study year\n\n\nCode# print(kruskal.test(vetrepos_score ~ study_year, data = raw_data))\nkruskal.test(vetrepos_score ~ study_year, data = raw_data)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  vetrepos_score by study_year\nKruskal-Wallis chi-squared = 124.28, df = 5, p-value &lt; 2.2e-16\n\nCodey1 &lt;- raw_data[ raw_data$study_year == 1, 'vetrepos_score']\ny2 &lt;- raw_data[ raw_data$study_year == 2, 'vetrepos_score']\ny3 &lt;- raw_data[ raw_data$study_year == 3, 'vetrepos_score']\ny4 &lt;- raw_data[ raw_data$study_year == 4, 'vetrepos_score']\ny5 &lt;- raw_data[ raw_data$study_year == 5, 'vetrepos_score']\ny6 &lt;- raw_data[ raw_data$study_year == 6, 'vetrepos_score']\n\nx &lt;- c(y1, y2, y3, y4, y5, y6)\ng &lt;- factor(rep(1:6, table(raw_data$study_year)),\n            labels = 1:6)\ndunn.test(x, g, method = 'bh') # fdr\n\n  Kruskal-Wallis rank sum test\n\ndata: x and g\nKruskal-Wallis chi-squared = 124.2758, df = 5, p-value = 0\n\n                             Comparison of x by g                              \n                             (Benjamini-Hochberg)                              \nCol Mean-|\nRow Mean |          1          2          3          4          5\n---------+-------------------------------------------------------\n       2 |  -3.131104\n         |    0.0015*\n         |\n       3 |  -6.698123  -4.259159\n         |    0.0000*    0.0000*\n         |\n       4 |  -7.465930  -5.162119  -0.959320\n         |    0.0000*    0.0000*     0.1807\n         |\n       5 |  -7.637413  -5.538093  -1.729820  -0.836484\n         |    0.0000*    0.0000*     0.0523     0.2014\n         |\n       6 |  -7.594304  -5.865184  -2.842328  -2.102684  -1.349013\n         |    0.0000*    0.0000*    0.0034*    0.0242*     0.1023\n\nalpha = 0.05\nReject Ho if p &lt;= alpha/2"
  },
  {
    "objectID": "R-code.html#figure-3-path-diagram-for-the-measurement-model",
    "href": "R-code.html#figure-3-path-diagram-for-the-measurement-model",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 3: Path diagram for the measurement model",
    "text": "Figure 3: Path diagram for the measurement model\nCoefficients from Table S4."
  },
  {
    "objectID": "R-code.html#figure-4-sum-scores-of-the-indicator-items",
    "href": "R-code.html#figure-4-sum-scores-of-the-indicator-items",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 4: Sum scores of the indicator items",
    "text": "Figure 4: Sum scores of the indicator items\n\ndistributions\npairwise correlations\n\n\nCode# pairwise correlation coefficients\ndata_figure4 &lt;- raw_data[\n  c(\n    \"raw_deep\",\n    \"raw_unreflective\", # items 1-3\n    \"raw_cynicism\",\n    \"raw_exhaustion\"\n  )\n]\n\npairs.panels(\n  x = data_figure4,\n  method = 'sp',\n  digits = 2,\n  ci = T\n) \n\n\n\nFigure 4. Sum scores of the indicator items\n\n\n\n\nCode# bootstrapping confidence intervals\nset.seed(1234)\ncor.ci(x = data_figure4, n.iter = n_iterations2, method = \"sp\", plot = FALSE)\n\nCall:corCi(x = x, keys = keys, n.iter = n.iter, p = p, overlap = overlap, \n    poly = poly, method = method, plot = plot, minlength = minlength, \n    n = n)\n\n Coefficients and bootstrapped confidence intervals \n                 rw_dp rw_nr rw_cy rw_xh\nraw_deep          1.00                  \nraw_unreflective -0.19  1.00            \nraw_cynicism     -0.18  0.42  1.00      \nraw_exhaustion    0.08  0.38  0.43  1.00\n\n scale correlations and bootstrapped confidence intervals \n            lower.emp lower.norm estimate upper.norm upper.emp    p\nrw_dp-rw_nr     -0.31      -0.31    -0.19      -0.06     -0.06 0.00\nrw_dp-rw_cy     -0.29      -0.30    -0.18      -0.05     -0.05 0.01\nrw_dp-rw_xh     -0.04      -0.04     0.08       0.21      0.20 0.18\nrw_nr-rw_cy      0.30       0.30     0.42       0.53      0.53 0.00\nrw_nr-rw_xh      0.26       0.27     0.38       0.49      0.49 0.00\nrw_cy-rw_xh      0.33       0.32     0.43       0.54      0.54 0.00"
  },
  {
    "objectID": "R-code.html#figure-5-path-diagram-for-the-full-model",
    "href": "R-code.html#figure-5-path-diagram-for-the-full-model",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 5: Path diagram for the full model",
    "text": "Figure 5: Path diagram for the full model\nCoefficients from table S7A."
  },
  {
    "objectID": "R-code.html#figure-6-standardized-residual-covariances-of-the-fitted-full-model",
    "href": "R-code.html#figure-6-standardized-residual-covariances-of-the-fitted-full-model",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 6: Standardized residual covariances of the fitted full model",
    "text": "Figure 6: Standardized residual covariances of the fitted full model\nDatasets:\n\nunweighted complete dataset (N=248)\nweighted dataset without university E (N=243)\ndown-sampled dataset (N=173, 1000 iterations)\n\nall residuals\nresidual between cynicism_1 and exhaustion_1 masked\n\n\n\n\nCode# unweighted dataset\nres_z = lavResiduals(fit_fullSEM, type = 'raw')$cov.z\nres_z = res_z[lower.tri(res_z)]\ndata &lt;- data.frame(\n  index = 1:length(res_z), \n  standardized_residual_covariance = res_z\n)\nshapiro.test(res_z) \n\n\n    Shapiro-Wilk normality test\n\ndata:  res_z\nW = 0.98773, p-value = 0.3549\n\n\nThe following code chunks won’t run on anonymous data.\n\nCode# weighted dataset\nres_z2 = lavResiduals(fit_weighted_fullSEM, type = 'raw')$cov.z\nres_z2 = res_z2[lower.tri(res_z2)]\ndata2 &lt;- data.frame(\n  index = 1:length(res_z2),\n  standardized_residual_covariance = res_z2\n)\n\n# down-sampled dataset\nall_residuals &lt;- list()\nall_residuals_masked &lt;- list()\nfor (i in 1:length(downsampled_data_standardized_residual_covariances)){\n  res_z3 &lt;- downsampled_data_standardized_residual_covariances[[i]]\n  # all residuals\n  all_residuals &lt;- append(all_residuals, res_z3[lower.tri(res_z3)]) \n  # residual[87] between cynicism_1. and exhaustion_1 is masked\n  all_residuals_masked &lt;- append(all_residuals_masked, res_z3[lower.tri(res_z3)][-87]) \n}\n\n# extraction of residual[87] from the list of all_residuals\nres_cyn1exh1 &lt;- unlist(all_residuals)[seq(87, length(all_residuals), length(res_z))]\nmean(res_cyn1exh1) #4.435283\n\n[1] 4.435283\n\nCoderange(res_cyn1exh1) # 3.440235 5.287087\n\n[1] 3.440235 5.287087\n\nCodequantile(res_cyn1exh1, c(0.025, 0.975)) # 3.803168 5.021121\n\n    2.5%    97.5% \n3.803168 5.021121 \n\nCode# preparation of dataset for plotting\n# all residuals\ndata3 &lt;- data.frame(\n  index = 1:length(unlist(all_residuals)),\n  standardized_residual_covariance= unlist(all_residuals)\n)\n# all residuals with mask on cynicism_1~~exhaustion_1 covariance term\ndata4 &lt;- data.frame(\n  index = 1:length(unlist(all_residuals_masked)),\n  standardized_residual_covariance= unlist(all_residuals_masked)\n)\n\n# prepare plots\np &lt;- ggplot(data = data3) + \n  geom_density(\n    aes(\n      y = after_stat(scaled),\n      x = standardized_residual_covariance\n    ),\n    fill = 'lightblue',\n    lwd = 0\n  ) +\n  geom_density(\n    data = data4, \n    aes(\n      y = after_stat(scaled),\n      x = standardized_residual_covariance\n    ),\n    fill = 'lightgreen',\n    lwd = 2, \n    linetype = 'dotted'\n  ) +\n  geom_density(\n    data = data3,\n    aes(\n      y = after_stat(scaled),\n      x = standardized_residual_covariance,\n    ),\n    lwd = 1\n  ) + \n  scale_y_continuous(\n    name = \"relative density\",\n    sec.axis = sec_axis(\n      transform = ~ . * max(data$index) / 1, \n      name = \"index\",\n      breaks = seq(0, 120, 30)\n    )\n  ) + \n  geom_point(\n    data = data2,\n    aes(\n      x = standardized_residual_covariance,\n      y = index / max(index)\n    ), \n    color = \"brown\", \n    alpha = 0.9,\n    size = 3\n  ) +\n  geom_point(\n    data = data,\n    aes(\n      x = standardized_residual_covariance,\n      y = index / max(index)\n    ), \n    color = 'blue',\n    alpha = 0.85,\n    size = 2\n  ) +\n  scale_x_continuous(limits = c(-6, 6)) + \n  labs(x = \"standardized residual covariance\")  + \n  theme_minimal() &\n  theme(\n    text = element_text(size = 12), \n    axis.text = element_text(size = 12)\n  ) \np\n\n\n\nFigure 6. Standardized residual covariances of the full SE models fitted to unweighted, weighted and down-sampled data"
  },
  {
    "objectID": "R-code.html#figure-7-comparison-of-parameter-estimates-from-full-se-models",
    "href": "R-code.html#figure-7-comparison-of-parameter-estimates-from-full-se-models",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 7: Comparison of parameter estimates from full SE models",
    "text": "Figure 7: Comparison of parameter estimates from full SE models\nFull SE model:\n\nunweighted complete dataset (N=248)\nweighted dataset without university E (N=243)\ndown-sampled dataset (N=173, 1000 iterations)\n\nmean values of parameter estimates fetched from Table S9\n\n\n\nFull SE model with freely estimated covariance between cynicism_1 and exhaustion_1\n\nunweighted complete dataset (N=248)\n\nThe following code chunk won’t run on anonymous data.\n\nCode# unweighted data\ndata &lt;- standardizedSolution(fit_fullSEM, output='data.frame') \n# downsampled_mean_value from Table S9\ndata$ds_mean_value &lt;- tableS9$mean.est.std \n# weighted data\ndata$wt_est.std &lt;- standardizedSolution(\n  fit_weighted_fullSEM, \n  output='data.frame'\n)$est.std \n\n# SEM with covariance term cynicism_1~~exhaustion_1\n# cynicism_1 ~~ exhaustion_1 covariance term excluded to match line numbers\ndata$cov_est.std &lt;- standardizedSolution(\n  fit_fullSEM_cov, \n  output='data.frame'\n)$est.std[-24] \n\ndata &lt;- subset(data, se != 0)\n\n# preparation of the labels\nestimates = list()\nfor (i in 1:nrow(data)){\n  estimates &lt;- append(estimates, paste(c(t(data[i,1:3])), collapse = ''))\n}\n\ndata$estimate &lt;- unlist(estimates)\ndata[nrow(data)+1,'estimate'] &lt;- 'factor loadings'\ndata[nrow(data)+1,'estimate'] &lt;- 'variances'\ndata[nrow(data)+1,'estimate'] &lt;- 'regression coefficients'\ndata[nrow(data)+1,'estimate'] &lt;- 'correlation coefficients'\n\nestimates &lt;- '\nfactor loadings\nf_deep=~deep_1\nf_deep=~deep_2\nf_deep=~deep_3\nf_deep=~deep_4\nf_unreflective=~unreflective_1\nf_unreflective=~unreflective_2\nf_unreflective=~unreflective_3\nf_cynicism=~cynicism_1\nf_cynicism=~cynicism_2\nf_cynicism=~cynicism_3\nf_exhaustion=~exhaustion_1\nf_exhaustion=~exhaustion_2\nf_exhaustion=~exhaustion_3\nf_exhaustion=~exhaustion_4\n\nregression coefficients\nscore_div100~f_deep\nscore_div100~study_year\nscore_div100~f_unreflective\nscore_div100~f_cynicism\nscore_div100~f_exhaustion\n\ncorrelation coefficients\nf_deep~~f_cynicism\nf_deep~~f_exhaustion\nf_deep~~f_unreflective\nf_unreflective~~f_cynicism\nf_unreflective~~f_exhaustion\nf_cynicism~~f_exhaustion\n\nvariances\ndeep_1~~deep_1\ndeep_2~~deep_2\ndeep_3~~deep_3\ndeep_4~~deep_4\nunreflective_1~~unreflective_1\nunreflective_2~~unreflective_2\nunreflective_3~~unreflective_3\ncynicism_1~~cynicism_1\ncynicism_2~~cynicism_2\ncynicism_3~~cynicism_3\nexhaustion_1~~exhaustion_1\nexhaustion_2~~exhaustion_2\nexhaustion_3~~exhaustion_3\nexhaustion_4~~exhaustion_4\nscore_div100~~score_div100\n'\n\nestimates &lt;- strsplit(x = estimates, split = \"\\n\")[[1]]\nestimates &lt;- estimates[estimates != \"\"]\ndata$estimate &lt;- factor(data$estimate, levels=rev(estimates))\n\ntick_labels &lt;- rev(data[with (data, order (estimate)), 'rhs'])\n\n# (1:nrow(data))[is.na(tick_labels)] # 1, 16, 22, 29\ntick_labels[1] &lt;- \"FACTOR LOADINGS\"\ntick_labels[16] &lt;- \"VETREPOS SCORE REGRESSIONS\"\ntick_labels[22] &lt;- \"CORRELATIONS\"\ntick_labels[29] &lt;- \"VARIANCES\"\ntick_labels[23:28] &lt;- estimates[23:28]\ntick_labels[nrow(data)] &lt;- \"score_div100\"\n\n# preparation of the plot\np1 &lt;- ggplot(\n  data = data, \n  aes(x=estimate, xend=estimate, y=ci.lower, yend=ci.upper)\n) \n\np2 &lt;- p1 +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(color = 'black', size = 12),\n    axis.line = element_line(color='black'),\n    axis.ticks = element_line(color = 'black'),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(linetype = 'dotted', colour = 'gray'),\n    panel.grid.major.x = element_blank(),\n    panel.ontop = FALSE\n  ) +\n  geom_hline(yintercept = 0, linetype = 'dashed', color = 'gray') +\n  geom_segment(color=\"darkgrey\", linewidth=1) +\n  geom_point(aes(x=estimate, y=est.std), color = \"darkgrey\", size = 2) +\n  geom_point(aes(x=estimate, y=wt_est.std), color = \"brown\", shape = \"I\", size = 7) +\n  geom_point(aes(x=estimate, y=cov_est.std), color = \"black\", shape = \"I\", size = 6) +\n  geom_point(aes(x=estimate, y=ds_mean_value), color = \"blue\", shape = \"I\", size = 5) +\n  coord_flip() +\n  labs(y = 'standardized value', x = '') +\n  scale_x_discrete(label = rev(tick_labels)) \n\np2\n\n\n\nFigure 7. Parameter estimates from full SE models fitted to unweighted, weighted and down-sampled data"
  },
  {
    "objectID": "R-code.html#figure-8-levels-of-latent-traits-across-study-years",
    "href": "R-code.html#figure-8-levels-of-latent-traits-across-study-years",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 8: Levels of latent traits across study years",
    "text": "Figure 8: Levels of latent traits across study years\nThe following code chunk won’t run on anonymous data.\n\nCodeydims = c(-2,2.2)\nlayout(\n  mat = matrix(c(1,2,3,4), nrow = 1), \n  widths = c(1,1,1,1), \n  heights = c(1.5,1.5,1.5,1.5),\n  respect = TRUE\n)\nboxplot(\n  f_deep ~ study_year, \n  complete_data, ylab = 'latent_trait_level', \n  main='Deep approach', \n  ylim=ydims\n)\nboxplot(\n  f_unreflective ~ study_year, \n  complete_data, ylab = 'latent_trait_level', \n  main='Unreflective approach', \n  ylim=ydims\n)\nboxplot(\n  f_cynicism ~ study_year, \n  complete_data, \n  ylab = 'latent_trait_level', \n  main='Cynicism', \n  ylim=ydims\n)\nboxplot(\n  f_exhaustion ~ study_year, \n  complete_data, \n  ylab = 'latent_trait_level', \n  main='Exhaustion', \n  ylim=ydims\n)\n\n\n\nFigure 8. Levels of traits across study years\n\n\n\nThe following code chunks won’t run on anonymous data.\n\nCode### statistical analysis\n# Mardia test failed\nmardiaKurtosis(complete_data[c(\"f_deep\", \"f_unreflective\", \"f_cynicism\", \"f_exhaustion\")]) \n\n        b2d           z           p \n25.99481143  2.26713339  0.02338208 \n\nCodemardiaSkew(complete_data[c(\"f_deep\", \"f_unreflective\", \"f_cynicism\", \"f_exhaustion\")]) \n\n         b1d          chi           df            p \n1.828695e+00 7.558606e+01 2.000000e+01 2.174916e-08 \n\nCode# 1-way anova\nkruskal.test(f_deep ~ study_year, complete_data) # NS\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  f_deep by study_year\nKruskal-Wallis chi-squared = 6.0169, df = 5, p-value = 0.3046\n\nCodekruskal.test(f_unreflective ~ study_year, complete_data) # NS\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  f_unreflective by study_year\nKruskal-Wallis chi-squared = 4.8859, df = 5, p-value = 0.43\n\nCodekruskal.test(f_cynicism ~ study_year, complete_data) # NS\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  f_cynicism by study_year\nKruskal-Wallis chi-squared = 1.3497, df = 5, p-value = 0.9297\n\nCodekruskal.test(f_exhaustion ~ study_year, complete_data) # NS\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  f_exhaustion by study_year\nKruskal-Wallis chi-squared = 2.6436, df = 5, p-value = 0.7547"
  },
  {
    "objectID": "R-code.html#figure-9-standardized-levels-of-latent-traits",
    "href": "R-code.html#figure-9-standardized-levels-of-latent-traits",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure 9: Standardized levels of latent traits",
    "text": "Figure 9: Standardized levels of latent traits\n\ndistributions\ncorrelations\n\n\nCodeset.seed(1234)\npairs.panels(\n  lavaan_traits, \n  method = 'sp',\n  digits = 2, \n  rug = FALSE, \n  ci = TRUE\n) # Figure 9\n\n\n\nFigure 9. Standardized levels of latent traits\n\n\n\n\nCodeset.seed(1234)\ncor.ci(\n  lavaan_traits, \n  n.iter = n_iterations2, \n  method = 'sp', \n  plot = FALSE\n)\n\nCall:corCi(x = x, keys = keys, n.iter = n.iter, p = p, overlap = overlap, \n    poly = poly, method = method, plot = plot, minlength = minlength, \n    n = n)\n\n Coefficients and bootstrapped confidence intervals \n               f_dep f_nrf f_cyn f_xhs\nf_deep          1.00                  \nf_unreflective -0.36  1.00            \nf_cynicism     -0.27  0.70  1.00      \nf_exhaustion    0.07  0.72  0.65  1.00\n\n scale correlations and bootstrapped confidence intervals \n            lower.emp lower.norm estimate upper.norm upper.emp    p\nf_dep-f_nrf     -0.48      -0.47    -0.36      -0.24     -0.24 0.00\nf_dep-f_cyn     -0.38      -0.38    -0.27      -0.14     -0.14 0.00\nf_dep-f_xhs     -0.05      -0.05     0.07       0.20      0.20 0.25\nf_nrf-f_cyn      0.61       0.61     0.70       0.77      0.77 0.00\nf_nrf-f_xhs      0.65       0.65     0.72       0.78      0.78 0.00\nf_cyn-f_xhs      0.56       0.55     0.65       0.72      0.72 0.00"
  },
  {
    "objectID": "R-code.html#figure-s1-model-comparison-original-vs.-covariance-term-at-cynicism_1exhaustion_1",
    "href": "R-code.html#figure-s1-model-comparison-original-vs.-covariance-term-at-cynicism_1exhaustion_1",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure S1: Model comparison: original vs. covariance term at cynicism_1~~exhaustion_1",
    "text": "Figure S1: Model comparison: original vs. covariance term at cynicism_1~~exhaustion_1\n\nCodedata &lt;- cbind(\n  standardizedSolution(fit_fullSEM, output='data.frame'),\n  # covariance term is removed to match data length\n  standardizedSolution(fit_fullSEM_cov, output='data.frame')[-24,] \n)\n\n# estimated value of the covariance term from the output of standardizedSolution()\n#               lhs op            rhs est.std    se      z pvalue ci.lower ci.upper\n# 24     cynicism_1 ~~   exhaustion_1   0.308 0.064  4.847  0.000    0.184    0.433\n\n\ncolnames(data)[10:18] &lt;- paste('cov.', colnames(data)[10:18], sep = '')\n\ndata &lt;- subset(data, se != 0)\n\n# preparation of labels\nestimates = list()\nfor (i in 1:nrow(data)){\n  estimates &lt;- append(estimates, paste(c(t(data[i,1:3])), collapse = ''))\n}\n\ndata$estimate &lt;- unlist(estimates)\ndata[nrow(data)+1,'estimate'] &lt;- 'factor loadings'\ndata[nrow(data)+1,'estimate'] &lt;- 'variances'\ndata[nrow(data)+1,'estimate'] &lt;- 'regression coefficients'\ndata[nrow(data)+1,'estimate'] &lt;- 'correlation coefficients'\n\nestimates &lt;- '\nfactor loadings\nf_deep=~deep_1\nf_deep=~deep_2\nf_deep=~deep_3\nf_deep=~deep_4\nf_unreflective=~unreflective_1\nf_unreflective=~unreflective_2\nf_unreflective=~unreflective_3\nf_cynicism=~cynicism_1\nf_cynicism=~cynicism_2\nf_cynicism=~cynicism_3\nf_exhaustion=~exhaustion_1\nf_exhaustion=~exhaustion_2\nf_exhaustion=~exhaustion_3\nf_exhaustion=~exhaustion_4\n\nregression coefficients\nscore_div100~f_deep\nscore_div100~study_year\nscore_div100~f_unreflective\nscore_div100~f_cynicism\nscore_div100~f_exhaustion\n\ncorrelation coefficients\nf_deep~~f_cynicism\nf_deep~~f_exhaustion\nf_deep~~f_unreflective\nf_unreflective~~f_cynicism\nf_unreflective~~f_exhaustion\nf_cynicism~~f_exhaustion\n\nvariances\ndeep_1~~deep_1\ndeep_2~~deep_2\ndeep_3~~deep_3\ndeep_4~~deep_4\nunreflective_1~~unreflective_1\nunreflective_2~~unreflective_2\nunreflective_3~~unreflective_3\ncynicism_1~~cynicism_1\ncynicism_2~~cynicism_2\ncynicism_3~~cynicism_3\nexhaustion_1~~exhaustion_1\nexhaustion_2~~exhaustion_2\nexhaustion_3~~exhaustion_3\nexhaustion_4~~exhaustion_4\nscore_div100~~score_div100\n'\n\nestimates &lt;- strsplit(x = estimates, split = \"\\n\")[[1]]\nestimates &lt;- estimates[estimates != \"\"]\ndata$estimate &lt;- factor(data$estimate, levels=rev(estimates))\n\ntick_labels &lt;- rev(data[with (data, order (estimate)), 'rhs'])\n\n# (1:nrow(data))[is.na(tick_labels)]\ntick_labels[1] &lt;- \"FACTOR LOADINGS\"\ntick_labels[16] &lt;- \"VETREPOS SCORE REGRESSIONS\"\ntick_labels[22] &lt;- \"CORRELATIONS\"\ntick_labels[29] &lt;- \"VARIANCES\"\ntick_labels[23:28] &lt;- estimates[23:28]\ntick_labels[nrow(data)] &lt;- \"score_div100\"\n\n# preparation of the plot\np_cleveland &lt;- ggplot(data = data) +\n  geom_segment( \n    aes(x=estimate, xend=estimate, y=ci.lower, yend=ci.upper), \n    color='gray', \n    linewidth=2\n  ) +\n  geom_hline(yintercept = 0, linetype = 'dashed', color = 'gray') + \n  geom_point( aes(x=estimate,y=ci.lower), color=\"darkgrey\", shape='I', size = 6) +\n  geom_point(aes(x=estimate, y=est.std), color = \"darkgrey\", shape='I', size = 8) + \n  geom_point(aes(x=estimate, y=ci.upper), color = \"darkgrey\", shape='I', size = 6) + \n  \n  geom_segment( \n    aes(x=estimate, xend=estimate, y=cov.ci.lower, yend=cov.ci.upper),\n    color='red', \n    linewidth=1, \n    linetype = 'dotted'\n  ) +\n  geom_point( aes(x=estimate,y=cov.ci.lower), color=\"red\", shape='I', size = 4) +\n  geom_point(aes(x=estimate, y=cov.est.std), color = \"red\", shape='I', size = 6) + \n  geom_point(aes(x=estimate, y=cov.ci.upper), color = \"red\", shape='I', size = 4) + \n  \n  coord_flip() +\n  theme_minimal() + \n  theme(\n    text = element_text(size = 12, color = 'black'),\n    axis.text = element_text(color = 'black', size = 12),\n    axis.line = element_line(color='black'),\n    axis.ticks = element_line(color = 'black'),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(linetype = 'dotted', colour = 'gray'),\n    panel.grid.major.x = element_blank(),\n    panel.ontop = FALSE\n  ) +\n  labs(y = 'standardized value', x = '' ) + \n  scale_x_discrete(label = rev(tick_labels))\n\np_cleveland\n\n\n\nFigure S1. Parameter estimates from full SE model with and without a covariance term between cynicism_1 and exhaustion_1"
  },
  {
    "objectID": "R-code.html#figure-s2-raw-sumscores-of-learning-approaches-cynicism-and-exhaustion-in-males-and-females",
    "href": "R-code.html#figure-s2-raw-sumscores-of-learning-approaches-cynicism-and-exhaustion-in-males-and-females",
    "title": "Knowledge attainment, learning approaches, and self-perceived study burnout among European veterinary students",
    "section": "Figure S2: Raw sumscores of learning approaches, cynicism and exhaustion in males and females",
    "text": "Figure S2: Raw sumscores of learning approaches, cynicism and exhaustion in males and females\nThe following code chunk won’t run on anonymous data.\n\nCodedata &lt;- raw_data\n\np1 &lt;- ggplot(data = data) + \n  geom_histogram(\n    aes(\n      x = raw_deep, \n      fill = gender == 1, \n    ), \n  position = 'identity', \n  alpha = 0.4,\n  bins = 17\n) +\ntheme_minimal() +\ntheme(\n  text = element_text(size = 12),\n  axis.line = element_line(color='black'),\n  axis.ticks = element_line(color = 'black'),\n  panel.grid.minor = element_blank(),\n  panel.grid.major = element_blank(),\n  panel.ontop = TRUE\n)\n\np2 &lt;- ggplot(data = data) + \n  geom_histogram(\n    aes(\n      x = raw_unreflective, \n      fill = gender == 1\n    ),\n    position = 'identity', \n    alpha = 0.4, \n    bins = 12\n  ) + \n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    axis.line = element_line(color='black'),\n    axis.ticks = element_line(color = 'black'),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.ontop = TRUE\n  )\n\n\np3 &lt;- ggplot(data = data) + \n  geom_histogram(\n    aes(\n      x = raw_cynicism, \n      fill = gender == 1\n    ),\n    position = 'identity', \n    alpha = 0.4, \n    bins = 13\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    axis.line = element_line(color='black'),\n    axis.ticks = element_line(color = 'black'),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.ontop = TRUE\n  )\n\n\np4 &lt;- ggplot(data = data) + \n  geom_histogram(\n    aes(\n      x = raw_exhaustion, \n      fill = gender == 1\n    ),\n    position = 'identity', \n    alpha = 0.4, \n    bins = 16\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    axis.line = element_line(color='black'),\n    axis.ticks = element_line(color = 'black'),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.ontop = TRUE\n  )\n\np_all &lt;- (p1 | p2  ) / (p3  | p4) +\n  plot_annotation(\n    # title = 'Raw sum scores of the scales in male and female students',\n    tag_levels = 'A'\n  ) +\n  plot_layout(guides = 'collect')  &\n  scale_fill_manual(\n    name = \"gender\",\n    values = c(\"TRUE\" = rgb(0,0,1), \"FALSE\" = rgb(1,0,0)),\n    # values = c(\"TRUE\" = rgb(0,0,1,0.1), \"FALSE\" = rgb(1,0,0,0.1)),\n    labels = c(\"female\", \"male\"),\n  ) \n\n\np_all\n\n\n\nFigure S2. Raw sum scores of scales in male and female students\n\n\nCode# statistical analysis with fdr adjustment for p-value (n = 4)\nkruskal.test(\n  x = c(\n    subset(data, gender == 1)[\"raw_deep\"],\n    subset(data, gender == 2)[\"raw_deep\"]\n  )\n)$p.value # NS 0.451\n\n[1] 0.4509818\n\nCodep.adjust(kruskal.test(\n  x = c(\n    subset(data, gender == 1)[\"raw_unreflective\"],\n    subset(data, gender == 2)[\"raw_unreflective\"]\n  )\n)$p.value, n = 4, 'fdr') # NS = 0.1988 \n\n[1] 0.1988126\n\nCodekruskal.test(\n  x = c(\n    subset(data, gender == 1)[\"raw_cynicism\"],\n    subset(data, gender == 2)[\"raw_cynicism\"]\n  )\n)$p.value # NS\n\n[1] 0.2575851\n\nCodekt &lt;- kruskal.test(\n  x = c(\n    subset(data, gender == 1)[\"raw_exhaustion\"],\n    subset(data, gender == 2)[\"raw_exhaustion\"]\n  )\n)\n\nkt\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  c(subset(data, gender == 1)[\"raw_exhaustion\"], subset(data, gender == 2)[\"raw_exhaustion\"])\nKruskal-Wallis chi-squared = 14.8, df = 1, p-value = 0.0001195\n\nCodep.adjust(kt$p.value, n=4, 'fdr')\n\n[1] 0.0004781081"
  }
]